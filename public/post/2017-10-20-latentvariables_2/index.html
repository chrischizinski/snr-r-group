<!DOCTYPE html>
<html lang="en-us">
    <head>
         
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Latent variable analysis. Part 2</title>
        <style>

    html body {
        font-family: 'Roboto', sans-serif;
        background-color: #FEFDFA;
    }

    :root {
        --accent: #D00000;
        --border-width:  5px ;
    }

</style>


<link rel="stylesheet" href="/css/main.css">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/hybrid.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
 


    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>

     <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/go.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/haskell.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/kotlin.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/swift.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/R.min.js"></script> 

    <script>hljs.initHighlightingOnLoad();</script>







<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>
 <meta name="generator" content="Hugo 0.30.2" />
        
        
        
        
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-48496439-3"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments)};
          gtag('js', new Date());

          gtag('config', 'UA-48496439-3');
        </script>
        
    </head>

    
    
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    

    <body>
         
        <nav class="navbar navbar-default navbar-fixed-top">

            <div class="container">

                <div class="navbar-header">

                    <a class="navbar-brand visible-xs" href="#">Latent variable analysis. Part 2</a>

                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>

                </div>

                <div class="collapse navbar-collapse">

                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">Home</a></li>
                            
                                <li><a href="/post/">Posts</a></li>
                            
                                <li><a href="/resources/">Resources</a></li>
                            
                        </ul>
                    

                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="mailto:cchizinski2@unl.edu"><i class="fa fa-envelope-o"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://github.com/chrischizinski/"><i class="fa fa-github"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://twitter.com/chrischizinski/"><i class="fa fa-twitter"></i></a></li>
                            
                        </ul>
                    

                </div>

            </div>

        </nav>


<main>

    <div class="item">

    
    
    

    
    

    <h4><a href="/post/2017-10-20-latentvariables_2/">Latent variable analysis. Part 2</a></h4>
    <h5>October 20, 2017</h5>
    
    <a href="/tags/applied-multivariate"><kbd class="item-tag">Applied Multivariate</kbd></a>
    

</div>


    <br> <div class="text-justify"><pre class="r"><code>library(psych)
library(GGally)
library(ggrepel)
library(gridExtra)
library(polycor)
library(poLCA)
library(tidyverse)</code></pre>
<div id="latent-variable-analysis" class="section level1">
<h1>Latent variable analysis</h1>
<div id="factor-analysis" class="section level2">
<h2>Factor analysis</h2>
<div id="exploratory-factor-analysis-continued" class="section level3">
<h3>Exploratory factor analysis (continued)</h3>
<p>Load the data</p>
<pre class="r"><code>goal_scale &lt;- read_csv(&quot;https://raw.githubusercontent.com/chrischizinski/SNR_R_Group/master/data/goal_scale.csv&quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   ags1 = col_integer(),
##   ags2 = col_integer(),
##   ags3 = col_integer(),
##   ags4 = col_integer(),
##   ags5 = col_integer(),
##   ags6 = col_integer(),
##   ags7 = col_integer(),
##   ags8 = col_integer(),
##   ags9 = col_integer(),
##   ags10 = col_integer(),
##   ags11 = col_integer(),
##   ags12 = col_integer()
## )</code></pre>
<pre class="r"><code>head(goal_scale)</code></pre>
<pre><code>## # A tibble: 6 x 12
##    ags1  ags2  ags3  ags4  ags5  ags6  ags7  ags8  ags9 ags10 ags11 ags12
##   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1     6     6     6     7     7     5     7     6     6     7     6     6
## 2     5     5     6     6     7     6     5     6     6     7     5     5
## 3     5     6     2     3     7     6     7     2     4     2     2     7
## 4     5     4     7     7     6     5     4     7     7     7     7     4
## 5     5     4     5     5     6     5     5     4     5     5     3     3
## 6     7     7     7     7     7     7     7     7     7     7     7     7</code></pre>
<p>Fit an EFA models with <code>factanal</code></p>
<pre class="r"><code>agoal.efa&lt;-factanal(~ags1+ags2+ags3+ags4+ags5+ags6+ags7+ags8+ags9+ags10+ags11+ ags12, factors=4, rotation=&quot;promax&quot;, data = goal_scale )

agoal.efa </code></pre>
<pre><code>## 
## Call:
## factanal(x = ~ags1 + ags2 + ags3 + ags4 + ags5 + ags6 + ags7 +     ags8 + ags9 + ags10 + ags11 + ags12, factors = 4, data = goal_scale,     rotation = &quot;promax&quot;)
## 
## Uniquenesses:
##  ags1  ags2  ags3  ags4  ags5  ags6  ags7  ags8  ags9 ags10 ags11 ags12 
## 0.487 0.335 0.279 0.342 0.557 0.388 0.104 0.005 0.231 0.201 0.300 0.306 
## 
## Loadings:
##       Factor1 Factor2 Factor3 Factor4
## ags1           0.667                 
## ags2                   0.844         
## ags3   0.864                         
## ags4   0.793           0.104  -0.116 
## ags5           0.565   0.123         
## ags6           0.764                 
## ags7           1.023  -0.120         
## ags8   0.756                   0.583 
## ags9   0.884                         
## ags10  0.866                   0.143 
## ags11  0.799                   0.195 
## ags12                  0.833         
## 
##                Factor1 Factor2 Factor3 Factor4
## SS loadings      4.122   2.404   1.461   0.426
## Proportion Var   0.344   0.200   0.122   0.036
## Cumulative Var   0.344   0.544   0.666   0.701
## 
## Factor Correlations:
##         Factor1 Factor2  Factor3  Factor4
## Factor1  1.0000  0.0919 -0.08477  0.20174
## Factor2  0.0919  1.0000  0.18936  0.66077
## Factor3 -0.0848  0.1894  1.00000 -0.00277
## Factor4  0.2017  0.6608 -0.00277  1.00000
## 
## Test of the hypothesis that 4 factors are sufficient.
## The chi square statistic is 77.4 on 24 degrees of freedom.
## The p-value is 0.000000157</code></pre>
<div id="loadings" class="section level4">
<h4>Loadings</h4>
<p>Challenge: To help interpret our loadings, lets create a visualization of those loadings.</p>
<pre class="r"><code>ld&lt;-loadings(agoal.efa)
loadings&lt;-as.data.frame(ld[,])

lt&lt;- data.frame(indicator = paste(&quot;ags&quot;,1:12, sep =&quot;&quot;),
           latent_traits = c(&quot;MAP&quot;, &quot;MAV&quot;, &quot;PAP&quot;, &quot;PAV&quot;, &quot;MAP&quot;,&quot;MAV&quot;, &quot;MAP&quot;, &quot;PAV&quot;, &quot;PAP&quot;, &quot;PAV&quot;, &quot;PAP&quot;, &quot;MAV&quot;))

loadings %&gt;% 
  rownames_to_column(&quot;indicator&quot;) %&gt;% 
  left_join(lt) %&gt;% 
  mutate(indicator = factor(indicator, levels = paste(&quot;ags&quot;,12:1, sep =&quot;&quot;))) %&gt;% 
  gather(factor, value, -indicator, - latent_traits) %&gt;% 
  mutate(value2 = ifelse(abs(value) &lt; 0.1, NA,  value),
         edge_colour = ifelse(is.na(value2), &quot;white&quot;, &quot;black&quot;))-&gt; loadings.long 


ggplot(data = loadings.long) +
  geom_point(aes(x = factor, y = indicator, fill = value2, shape = latent_traits, colour = edge_colour), size = 8) +
  scale_colour_manual(values= c(&quot;white&quot; = &quot;white&quot;, &quot;black&quot; = &quot;black&quot;), guide = FALSE) +
  scale_fill_gradient2(na.value = &quot;white&quot;, mid = &quot;blue&quot;, high = &quot;red&quot;, low = &quot;yellow&quot;,limits = c(-1,1.05)) +
  scale_shape_manual(values = c(&quot;MAP&quot; = 21, &quot;MAV&quot; = 22, &quot;PAP&quot; = 23, &quot;PAV&quot; = 24)) +
  labs(fill = &quot;Loading&quot;, shape = &quot;Latent\ntrait&quot;) +
  theme_classic()</code></pre>
<p><img src="/post/2017-10-20-LatentVariables_2_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<ol style="list-style-type: decimal">
<li>We see some cross loading by indicators: <code>ags4</code>, <code>ags5</code>, <code>ags8</code>,<code>ags10</code>, <code>ags11</code></li>
<li>We also see that each factor has multiple latent traits associated with it, suggesting this solution does not conform to the <em>a priori </em> 4-factor solution</li>
</ol>
</div>
<div id="variation-explained-by-each-factor" class="section level4">
<h4>Variation explained by each factor</h4>
<p>While this is printed using <code>loadings</code> it is not easily extracted using that function so we need to calculate it ourselves. The sum of squared loadings (SS_loadings) is taken by multiplying the loadings by itself and then taking the sum of the columns. The proportional variance is calculated by dividing the SS_loadings by the number of potential factors (i.e., number of rows). The cumulative variance is calculated by taking the cumulative sum of the proportional variances.</p>
<pre class="r"><code>SS_loadings&lt;-colSums(loadings*loadings)
SS_loadings</code></pre>
<pre><code>##   Factor1   Factor2   Factor3   Factor4 
## 4.1224976 2.4040942 1.4607053 0.4260008</code></pre>
<pre class="r"><code>Prop_var &lt;- SS_loadings / nrow(loadings)
Prop_var</code></pre>
<pre><code>##    Factor1    Factor2    Factor3    Factor4 
## 0.34354146 0.20034118 0.12172544 0.03550007</code></pre>
<pre class="r"><code>Cuml_var &lt;-cumsum(Prop_var)
Cuml_var</code></pre>
<pre><code>##   Factor1   Factor2   Factor3   Factor4 
## 0.3435415 0.5438826 0.6656081 0.7011082</code></pre>
</div>
<div id="relationship-among-factors" class="section level4">
<h4>Relationship among factors</h4>
<p>Looking at the output from <code>factanal()</code>, we see that generally there is low correlation between factors except 2 and 4. High correlation (&gt;0.7) between factors is an indication for redundancy among factors</p>
</div>
<div id="model-fit" class="section level4">
<h4>Model fit</h4>
<p>At the very bottom of the output, we see the chi-square test for goodness of fit. The chi-square was 77.4044866 with 24 df and an associated p-value of 1.567982410^{-7}. This value is &lt;0.05 leading us to reject the null hypothesis that the model adequately fits the data and suggesting a four-factor model is not appropriate. However, given chi-square tests sensitivity to sample size and stringent null hypothesis of exact model data fit, this test is probably not sufficiently reliable. Further, the <em>a priori</em> information about the latent traits exist on multiple factors.</p>
</div>
</div>
<div id="so-how-many-factors-is-appropriate" class="section level3">
<h3>So how many factors is appropriate?</h3>
<pre class="r"><code>psych::fa.parallel(goal_scale, fa=&quot;fa&quot;, fm=&quot;ml&quot;)</code></pre>
<p><img src="/post/2017-10-20-LatentVariables_2_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  3  and the number of components =  NA</code></pre>
<p>So lets look at a 3 factor solution.</p>
<pre class="r"><code>agoal.efa3&lt;-factanal(~ags1+ags2+ags3+ags4+ags5+ags6+ags7+ags8+ags9+ags10+ags11+ ags12, factors=3, rotation=&quot;promax&quot;, data = goal_scale)

agoal.efa3</code></pre>
<pre><code>## 
## Call:
## factanal(x = ~ags1 + ags2 + ags3 + ags4 + ags5 + ags6 + ags7 +     ags8 + ags9 + ags10 + ags11 + ags12, factors = 3, data = goal_scale,     rotation = &quot;promax&quot;)
## 
## Uniquenesses:
##  ags1  ags2  ags3  ags4  ags5  ags6  ags7  ags8  ags9 ags10 ags11 ags12 
## 0.482 0.424 0.313 0.402 0.558 0.385 0.120 0.266 0.251 0.188 0.297 0.200 
## 
## Loadings:
##       Factor1 Factor2 Factor3
## ags1           0.677         
## ags2                   0.714 
## ags3   0.841          -0.110 
## ags4   0.761                 
## ags5           0.602         
## ags6           0.764         
## ags7           0.999  -0.101 
## ags8   0.832  -0.126   0.138 
## ags9   0.872                 
## ags10  0.896                 
## ags11  0.835                 
## ags12                  0.916 
## 
##                Factor1 Factor2 Factor3
## SS loadings      4.246   2.450   1.415
## Proportion Var   0.354   0.204   0.118
## Cumulative Var   0.354   0.558   0.676
## 
## Factor Correlations:
##         Factor1 Factor2 Factor3
## Factor1   1.000   0.070   0.191
## Factor2   0.070   1.000   0.633
## Factor3   0.191   0.633   1.000
## 
## Test of the hypothesis that 3 factors are sufficient.
## The chi square statistic is 157.52 on 33 degrees of freedom.
## The p-value is 3.69e-18</code></pre>
<pre class="r"><code>loadings3&lt;-as.data.frame(loadings(agoal.efa3)[,])
loadings3%&gt;% 
  rownames_to_column(&quot;indicator&quot;) %&gt;% 
  left_join(lt) %&gt;% 
  mutate(indicator = factor(indicator, levels = paste(&quot;ags&quot;,12:1, sep =&quot;&quot;))) %&gt;% 
  gather(factor, value, -indicator, - latent_traits) %&gt;% 
  mutate(value2 = ifelse(value &lt; 0.1, NA,  value),
         edge_colour = ifelse(is.na(value2), &quot;white&quot;, &quot;black&quot;))-&gt; loadings3.long </code></pre>
<pre><code>## Joining, by = &quot;indicator&quot;</code></pre>
<pre class="r"><code>ggplot(data = loadings3.long) +
  geom_point(aes(x = factor, y = indicator, fill = value2, shape = latent_traits, colour = edge_colour), size = 8) +
  scale_colour_manual(values= c(&quot;white&quot; = &quot;white&quot;, &quot;black&quot; = &quot;black&quot;), guide = FALSE) +
  scale_fill_gradient2(na.value = &quot;white&quot;, mid = &quot;blue&quot;, high = &quot;red&quot;, low = &quot;yellow&quot;,limits = c(-1,1.05)) +
  scale_shape_manual(values = c(&quot;MAP&quot; = 21, &quot;MAV&quot; = 22, &quot;PAP&quot; = 23, &quot;PAV&quot; = 24)) +
  labs(fill = &quot;Loading&quot;, shape = &quot;Latent\ntrait&quot;) +
  theme_classic()</code></pre>
<p><img src="/post/2017-10-20-LatentVariables_2_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<div id="scores" class="section level4">
<h4>Scores</h4>
<p>Factor scores are linear combinations of the observed variables which consider what is shared between the item and the factor (i.e., shared variance) and what is not measured (i.e., the uniqueness or error term variance)</p>
<p><a href="https://stats.stackexchange.com/questions/126885/methods-to-compute-factor-scores-and-what-is-the-score-coefficient-matrix-in">source</a></p>
<p>Creates a new variable for each factor in the final solution using several methods:</p>
<ul>
<li><p>Regression method maximizes correlation between factor scores and unknown true values of that factor (i.e. maximizes the statistical validity), but the scores are somewhat biased and they somewhat incorrectly correlate between factors (e.g., they correlate even when factors in a solution are orthogonal). These are least-squares estimates.</p></li>
<li><p>PCA’s method is also least squares, but with less statistical validity. They are faster to compute; they are not often used in factor analysis nowadays, due to computers. (In PCA, this method is native and optimal.)</p></li>
<li><p>Bartlett’s scores are unbiased estimates of true factor values. The scores are computed to correlate accurately with true, unknown values of other factors (e.g. not to correlate with them in orthogonal solution, for example). However, they still may correlate inaccurately with factor scores computed for other factors. These are maximum-likelihood (under multivariate normality of XX assumption) estimates.</p></li>
<li><p>Anderson-Rubin / McDonald-Anderson-Rubin and Green’s scores are called correlation preserving because are computed to correlate accurately with factor scores of other factors. Correlations between factor scores equal the correlations between the factors in the solution (so in orthogonal solution, for instance, the scores will be perfectly uncorrelated). But the scores are somewhat biased and their validity may be modest.</p></li>
</ul>
<p>To obtain a score using <code>factanal</code> you need to specify the scores option.</p>
<pre class="r"><code>agoal.efa3&lt;-factanal(~ags1+ags2+ags3+ags4+ags5+ags6+ags7+ags8+ags9+ags10+ags11+ ags12, factors=3, rotation=&quot;promax&quot;, data = goal_scale, scores = &quot;Bartlett&quot;)

efa_scores &lt;- agoal.efa3$scores %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;obs&quot;) %&gt;% na.omit()

set.seed(1234)

sub_efa_scores &lt;- efa_scores[sample(25, replace = FALSE),]


a&lt;- ggplot(data = sub_efa_scores) + 
  geom_point(aes(x = Factor1, y = Factor2), colour = &quot;red&quot;, alpha = 0.5) +
  geom_text_repel(aes(x = Factor1, y = Factor2, label = obs)) +
  theme_classic()

b&lt;- ggplot(data = sub_efa_scores) + 
  geom_point(aes(x = Factor2, y = Factor3), colour = &quot;red&quot;, alpha = 0.5) +
  geom_text_repel(aes(x = Factor2, y = Factor3, label = obs)) +
  theme_classic()

c&lt;- ggplot(data = sub_efa_scores) + 
  geom_point(aes(x = Factor1, y = Factor3), colour = &quot;red&quot;, alpha = 0.5) +
  geom_text_repel(aes(x = Factor1, y = Factor3, label = obs)) +
  theme_classic()

grid.arrange(a,b,c, ncol = 3)</code></pre>
<p><img src="/post/2017-10-20-LatentVariables_2_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Factor scores are easy to create but a couple words of caution should be used in using these.</p>
<ol style="list-style-type: decimal">
<li>factor scores are sensitive to the factor extraction method and rotation method used</li>
<li>The problem of “indeterminacy” of the scores, which means that there is not a
unique solution for the factor analysis results and, theoretically, an infinite number of solutions could account for the relationships between the items and factor(s).</li>
</ol>
<p>There are other solutions that are better if you plan to use “scores” or individual identities</p>
</div>
</div>
<div id="fit-an-efa-models-with-psychfa" class="section level3">
<h3>Fit an EFA models with <code>psych::fa</code></h3>
<pre class="r"><code>agoal.efa.4&lt;-fa(goal_scale , nfactors=3, residuals=TRUE, rotate=&quot;promax&quot;,SMC=TRUE, fm=&quot;pa&quot;)</code></pre>
<pre><code>## Loading required namespace: GPArotation</code></pre>
<pre class="r"><code>agoal.efa.4</code></pre>
<pre><code>## Factor Analysis using method =  pa
## Call: fa(r = goal_scale, nfactors = 3, rotate = &quot;promax&quot;, residuals = TRUE, 
##     SMC = TRUE, fm = &quot;pa&quot;)
## Standardized loadings (pattern matrix) based upon correlation matrix
##         PA1   PA2   PA3   h2   u2 com
## ags1   0.04  0.72  0.04 0.56 0.44 1.0
## ags2  -0.02  0.10  0.74 0.64 0.36 1.0
## ags3   0.86  0.08 -0.13 0.71 0.29 1.1
## ags4   0.75  0.05  0.04 0.59 0.41 1.0
## ags5  -0.07  0.64  0.06 0.46 0.54 1.0
## ags6   0.04  0.73  0.05 0.58 0.42 1.0
## ags7   0.00  0.98 -0.09 0.85 0.15 1.0
## ags8   0.82 -0.14  0.15 0.73 0.27 1.1
## ags9   0.87  0.08 -0.08 0.75 0.25 1.0
## ags10  0.89  0.00  0.02 0.80 0.20 1.0
## ags11  0.84 -0.08  0.02 0.71 0.29 1.0
## ags12  0.02  0.04  0.81 0.71 0.29 1.0
## 
##                        PA1  PA2  PA3
## SS loadings           4.25 2.52 1.33
## Proportion Var        0.35 0.21 0.11
## Cumulative Var        0.35 0.56 0.67
## Proportion Explained  0.53 0.31 0.16
## Cumulative Proportion 0.53 0.84 1.00
## 
##  With factor correlations of 
##      PA1  PA2  PA3
## PA1 1.00 0.08 0.22
## PA2 0.08 1.00 0.60
## PA3 0.22 0.60 1.00
## 
## Mean item complexity =  1
## Test of the hypothesis that 3 factors are sufficient.
## 
## The degrees of freedom for the null model are  66  and the objective function was  8.05 with Chi Square of  3430.61
## The degrees of freedom for the model are 33  and the objective function was  0.37 
## 
## The root mean square of the residuals (RMSR) is  0.02 
## The df corrected root mean square of the residuals is  0.03 
## 
## The harmonic number of observations is  428 with the empirical chi square  30.65  with prob &lt;  0.58 
## The total number of observations was  432  with Likelihood Chi Square =  158.95  with prob &lt;  2.1e-18 
## 
## Tucker Lewis Index of factoring reliability =  0.925
## RMSEA index =  0.095  and the 90 % confidence intervals are  0.08 0.109
## BIC =  -41.31
## Fit based upon off diagonal values = 1
## Measures of factor score adequacy             
##                                                    PA1  PA2  PA3
## Correlation of (regression) scores with factors   0.97 0.96 0.91
## Multiple R square of scores with factors          0.94 0.91 0.82
## Minimum correlation of possible factor scores     0.88 0.82 0.64</code></pre>
<ul>
<li><p>Root mean square error of approximation (RMSEA): By convention, values of RMSEA &lt; 0.05 are taken to indicate good model fit,
and values between 0.05 and 0.08 are seen as indicative of adequate model fit and &gt; 0.08 = poor fit.</p></li>
<li><p>Tucker–Lewis index (TLI): a model is considered to exhibit good fit is when the values of CFI and TLI are 0.95 or higher</p></li>
</ul>
</div>
<div id="was-this-all-approporiate-given-our-data" class="section level3">
<h3>Was this all approporiate given our data?</h3>
<p>12 questions with results representing a 7-point likert-type scale from 430 college students</p>
<p>In some cases, the measurement scale for data is ordinal, but the variable is treated as continuous. For example, a Likert scale that contains five values - strongly agree, agree, neither agree nor disagree, disagree, and strongly disagree - is ordinal</p>
<p>However, where a Likert scale contains seven or more value - strongly agree, moderately agree, agree, neither agree nor disagree, disagree, moderately disagree, and strongly disagree - the underlying scale is sometimes treated as continuous (although where you should do this is a cause of great dispute).</p>
<p>Lets look at the correlations first as nominal (as we have done above).</p>
<pre class="r"><code>corr_plot1&lt;-ggcorr(data = NULL,
                    cor_matrix = as.data.frame(agoal.efa3$correlation),
                    palette = &quot;RdGy&quot;, 
                   label = TRUE, 
                   label_round = 2,
                   label_size =4, 
                   label_color = &quot;black&quot;)

corr_plot1</code></pre>
<p><img src="/post/2017-10-20-LatentVariables_2_files/figure-html/unnamed-chunk-11-1.png" width="768" /></p>
<p>There is a couple ways we can have “categorical” type data. 1st is <em>nominal</em> where there are not levels in the data (e.g., <code>red , green, blue</code>) and this is created using <code>factor()</code>. 2nd is <em>ordinal</em> where we do have levels in the data (e.g., (<code>disagree &lt; neutral &lt; agree</code>) and this is created using <code>ordered()</code></p>
<pre class="r"><code>goal_scale  %&gt;% 
  na.omit() %&gt;% 
  mutate_all(ordered) %&gt;% 
  as.data.frame()-&gt; goal_ordered

try(factanal(~ags1+ags2+ags3+ags4+ags5+ags6+ags7+ags8+ags9+ags10+ags11+ ags12, factors=3, rotation=&quot;promax&quot;, data = goal_ordered))</code></pre>
<p><strong>DOES NOT WORK</strong></p>
<p>But we do have some options. We can use the <code>polycor</code> package to generate our own polychoric correlation matrices. <strong>NOTE</strong> You should probably use <code>ML=TRUE</code>, but this takes a real long time so for the purposes of this exercise we will not use it.</p>
<pre class="r"><code>pc_goals&lt;-hetcor(goal_ordered)</code></pre>
<pre><code>## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced

## Warning in log(P): NaNs produced</code></pre>
<pre class="r"><code>corr_plot2&lt;-ggcorr(data = NULL,
                    cor_matrix = as.data.frame(pc_goals$correlation),
                    palette = &quot;RdGy&quot;, 
                   label = TRUE, 
                   label_round = 2,
                   label_size =4, 
                   label_color = &quot;black&quot;)

grid.arrange(corr_plot1 + labs(title = &quot;Nominal&quot;) + theme(plot.title = element_text(hjust = 1, size = 22)), 
             corr_plot2 + labs(title = &quot;Ordinal&quot;) + theme(plot.title = element_text(hjust = 1, size = 22)),
             ncol = 2)</code></pre>
<p><img src="/post/2017-10-20-LatentVariables_2_files/figure-html/unnamed-chunk-13-1.png" width="960" /></p>
<p>We can see that there tends to be a higher values in the ordinal.</p>
<p>Does this change the factor analysis?</p>
<pre class="r"><code>agoal.efa.ordered&lt;-fa(r=pc_goals$correlations, 
                      nfactors=3, 
                      residuals=TRUE, rotate=&quot;promax&quot;,SMC=TRUE, fm=&quot;pa&quot;)


agoal.efa.ordered</code></pre>
<pre><code>## Factor Analysis using method =  pa
## Call: fa(r = pc_goals$correlations, nfactors = 3, rotate = &quot;promax&quot;, 
##     residuals = TRUE, SMC = TRUE, fm = &quot;pa&quot;)
## 
##  Warning: A Heywood case was detected. 
## Standardized loadings (pattern matrix) based upon correlation matrix
##         PA1   PA2   PA3   h2    u2 com
## ags1   0.03  0.76  0.04 0.62 0.378 1.0
## ags2   0.00  0.24  0.62 0.63 0.374 1.3
## ags3   0.87  0.08 -0.13 0.74 0.258 1.1
## ags4   0.82  0.09  0.00 0.70 0.300 1.0
## ags5  -0.09  0.66  0.13 0.55 0.448 1.1
## ags6   0.04  0.79  0.01 0.65 0.352 1.0
## ags7   0.02  1.04 -0.13 0.93 0.067 1.0
## ags8   0.86 -0.15  0.15 0.79 0.214 1.1
## ags9   0.92  0.08 -0.08 0.83 0.170 1.0
## ags10  0.92  0.00  0.03 0.87 0.134 1.0
## ags11  0.87 -0.11  0.06 0.77 0.229 1.0
## ags12  0.02  0.09  0.87 0.87 0.131 1.0
## 
##                        PA1  PA2  PA3
## SS loadings           4.66 2.95 1.34
## Proportion Var        0.39 0.25 0.11
## Cumulative Var        0.39 0.63 0.75
## Proportion Explained  0.52 0.33 0.15
## Cumulative Proportion 0.52 0.85 1.00
## 
##  With factor correlations of 
##      PA1  PA2  PA3
## PA1 1.00 0.09 0.20
## PA2 0.09 1.00 0.63
## PA3 0.20 0.63 1.00
## 
## Mean item complexity =  1.1
## Test of the hypothesis that 3 factors are sufficient.
## 
## The degrees of freedom for the null model are  66  and the objective function was  10.48
## The degrees of freedom for the model are 33  and the objective function was  0.53 
## 
## The root mean square of the residuals (RMSR) is  0.02 
## The df corrected root mean square of the residuals is  0.03 
## 
## Fit based upon off diagonal values = 1
## Measures of factor score adequacy             
##                                                    PA1  PA2  PA3
## Correlation of (regression) scores with factors   0.98 0.98 0.94
## Multiple R square of scores with factors          0.96 0.96 0.89
## Minimum correlation of possible factor scores     0.92 0.91 0.77</code></pre>
<p>Note the “Heywood case was detected.” Heywood cases [are] negative estimates of variances or correlation estimates greater than one in absolute value.</p>
</div>
</div>
</div>
</div>

    
    

    

        <h4 class="page-header">Related</h4>

         <div class="item">

    
    
    

    
    

    <h4><a href="/post/2017-11-17-differencesbetweengroups/">Applied Multivariate: Identifying differences between groups</a></h4>
    <h5>November 17, 2017</h5>
    
    <a href="/tags/applied-multivariate"><kbd class="item-tag">Applied Multivariate</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4><a href="/post/2017-11-09-latentvariables_3/">Latent variable analysis. Part 3</a></h4>
    <h5>November 9, 2017</h5>
    
    <a href="/tags/applied-multivariate"><kbd class="item-tag">Applied Multivariate</kbd></a>
    

</div>
  <div class="item">

    
    
    

    
    

    <h4><a href="/post/2017-10-13-latentvariables_1/">Latent variable analysis. Part 1</a></h4>
    <h5>October 13, 2017</h5>
    
    <a href="/tags/applied-multivariate"><kbd class="item-tag">Applied Multivariate</kbd></a>
    

</div>
 

    

    

        <h4 class="page-header">Comments</h4>

        <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "snrrgroup" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    

</main>

        <footer>

            <p class="copyright text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io">Hugo</a> and <a href="https://github.com/calintat/minimal">Minimal</a></p>

        </footer>
       
    </body>

</html>

