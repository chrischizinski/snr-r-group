build-last-errors="[]"
build-last-errors-base-dir=""
build-last-outputs="[{\"output\":\"==> rmarkdown::render_site(encoding = 'UTF-8')\\n\\n\",\"type\":0},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:10:57 2018 \\n\",\"type\":1},{\"output\":\"Warning: You are recommended to ignore certain files in config.toml: set the option ignoreFiles = [\\\"\\\\\\\\.Rmd$\\\", \\\"\\\\\\\\.Rmarkdown$\\\", \\\"_files$\\\", \\\"_cache$\\\"]\\n\",\"type\":2},{\"output\":\"Rendering content/post/2015-07-23-r-rmarkdown.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:10:58 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-08-12-SimilarityDistance.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:10:59 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-08-26-RBasics.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:11:03 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-09-02-DataStructures.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:11:05 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-09-09-DataInput.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:11:06 2018 \\n\",\"type\":1},{\"output\":\"read_excel               package:readxl                R Documentation\\n\\n_\\bR_\\be_\\ba_\\bd _\\bx_\\bl_\\bs _\\ba_\\bn_\\bd _\\bx_\\bl_\\bs_\\bx _\\bf_\\bi_\\bl_\\be_\\bs.\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     Read xls and xlsx files.\\n\\n     While 'read_excel()' auto detects the format from the file\\n     extension, 'read_xls()' and 'read_xlsx()' can be used to read\\n     files without extension.\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n     read_excel(path, sheet = NULL, range = NULL, col_names = TRUE,\\n       col_types = NULL, na = \\\"\\\", trim_ws = TRUE, skip = 0, n_max = Inf,\\n       guess_max = min(1000, n_max))\\n     \\n     read_xls(path, sheet = NULL, range = NULL, col_names = TRUE,\\n       col_types = NULL, na = \\\"\\\", trim_ws = TRUE, skip = 0, n_max = Inf,\\n       guess_max = min(1000, n_max))\\n     \\n     read_xlsx(path, sheet = NULL, range = NULL, col_names = TRUE,\\n       col_types = NULL, na = \\\"\\\", trim_ws = TRUE, skip = 0, n_max = Inf,\\n       guess_max = min(1000, n_max))\\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\n    path: Path to the xls/xlsx file\\n\\n   sheet: Sheet to read. Either a string (the name of a sheet), or an\\n          integer (the position of the sheet). Ignored if the sheet is\\n          specified via 'range'. If neither argument specifies the\\n          sheet, defaults to the first sheet.\\n\\n   range: A cell range to read from, as described in\\n          cell-specification. Includes typical Excel ranges like\\n          \\\"B3:D87\\\", possibly including the sheet name like\\n          \\\"Budget!B2:G14\\\", and more. Interpreted strictly, even if the\\n          range forces the inclusion of leading or trailing empty rows\\n          or columns. Takes precedence over 'skip', 'n_max' and\\n          'sheet'.\\n\\ncol_names: 'TRUE' to use the first row as column names, 'FALSE' to get\\n          default names, or a character vector giving a name for each\\n          column. If user provides 'col_types' as a vector, 'col_names'\\n          can have one entry per column, i.e. have the same length as\\n          'col_types', or one entry per unskipped column.\\n\\ncol_types: Either 'NULL' to guess all from the spreadsheet or a\\n          character vector containing one entry per column from these\\n          options: \\\"skip\\\", \\\"guess\\\", \\\"logical\\\", \\\"numeric\\\", \\\"date\\\",\\n          \\\"text\\\" or \\\"list\\\". If exactly one 'col_type' is specified, it\\n          will be recycled. The content of a cell in a skipped column\\n          is never read and that column will not appear in the data\\n          frame output. A list cell loads a column as a list of length\\n          1 vectors, which are typed using the type guessing logic from\\n          'col_types = NULL', but on a cell-by-cell basis.\\n\\n      na: Character vector of strings to use for missing values. By\\n          default, readxl treats blank cells as missing data.\\n\\n trim_ws: Should leading and trailing whitespace be trimmed?\\n\\n    skip: Minimum number of rows to skip before reading anything, be it\\n          column names or data. Leading empty rows are automatically\\n          skipped, so this is a lower bound. Ignored if 'range' is\\n          given.\\n\\n   n_max: Maximum number of data rows to read. Trailing empty rows are\\n          automatically skipped, so this is an upper bound on the\\n          number of rows in the returned tibble. Ignored if 'range' is\\n          given.\\n\\nguess_max: Maximum number of data rows to use for guessing column\\n          types.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\n     A tibble\\n\\n_\\bS_\\be_\\be _\\bA_\\bl_\\bs_\\bo:\\n\\n     cell-specification for more details on targetting cells with the\\n     'range' argument\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     datasets <- readxl_example(\\\"datasets.xlsx\\\")\\n     read_excel(datasets)\\n     \\n     # Specify sheet either by position or by name\\n     read_excel(datasets, 2)\\n     read_excel(datasets, \\\"mtcars\\\")\\n     \\n     # Skip rows and use default column names\\n     read_excel(datasets, skip = 148, col_names = FALSE)\\n     \\n     # Recycle a single column type\\n     read_excel(datasets, col_types = \\\"text\\\")\\n     \\n     # Specify some col_types and guess others\\n     read_excel(datasets, col_types = c(\\\"text\\\", \\\"guess\\\", \\\"numeric\\\", \\\"guess\\\", \\\"guess\\\"))\\n     \\n     # Accomodate a column with disparate types via col_type = \\\"list\\\"\\n     df <- read_excel(readxl_example(\\\"clippy.xlsx\\\"), col_types = c(\\\"text\\\", \\\"list\\\"))\\n     df\\n     df$value\\n     sapply(df$value, class)\\n     \\n     # Limit the number of data rows read\\n     read_excel(datasets, n_max = 3)\\n     \\n     # Read from an Excel range using A1 or R1C1 notation\\n     read_excel(datasets, range = \\\"C1:E7\\\")\\n     read_excel(datasets, range = \\\"R1C2:R2C5\\\")\\n     \\n     # Specify the sheet as part of the range\\n     read_excel(datasets, range = \\\"mtcars!B1:D5\\\")\\n     \\n     # Read only specific rows or columns\\n     read_excel(datasets, range = cell_rows(102:151), col_names = FALSE)\\n     read_excel(datasets, range = cell_cols(\\\"B:D\\\"))\\n     \\n\\n\",\"type\":1},{\"output\":\"read_sas                 package:haven                 R Documentation\\n\\n_\\bR_\\be_\\ba_\\bd _\\ba_\\bn_\\bd _\\bw_\\br_\\bi_\\bt_\\be _\\bS_\\bA_\\bS _\\bf_\\bi_\\bl_\\be_\\bs.\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     Reading supports both sas7bdat files and the accompanying sas7bdat\\n     files that SAS uses to record value labels. Writing value labels\\n     is not currently supported.\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n     read_sas(data_file, catalog_file = NULL, encoding = NULL,\\n       catalog_encoding = encoding, cols_only = NULL)\\n     \\n     write_sas(data, path)\\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\ndata_file, catalog_file: Path to data and catalog files. The files are\\n          processed with 'datasource()'.\\n\\nencoding, catalog_encoding: The character encoding used for the\\n          `data_file` and `catalog_encoding` respectively. A value of\\n          `NULL` uses the encoding specified in the file; use this\\n          argument to override it if it is incorrect.\\n\\ncols_only: A character vector giving an experimental way to read in\\n          only specified columns.\\n\\n    data: Data frame to write.\\n\\n    path: Path to file where the data will be written.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\n     A tibble, data frame variant with nice defaults.\\n\\n     Variable labels are stored in the \\\"label\\\" attribute of each\\n     variable.  It is not printed on the console, but the RStudio\\n     viewer will show it.\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     path <- system.file(\\\"examples\\\", \\\"iris.sas7bdat\\\", package = \\\"haven\\\")\\n     read_sas(path)\\n     \\n\\n\",\"type\":1},{\"output\":\"read_spss                package:haven                 R Documentation\\n\\n_\\bR_\\be_\\ba_\\bd _\\bS_\\bP_\\bS_\\bS (_\\bS_\\bA_\\bV & _\\bP_\\bO_\\bR) _\\bf_\\bi_\\bl_\\be_\\bs. _\\bW_\\br_\\bi_\\bt_\\be _\\bS_\\bA_\\bV _\\bf_\\bi_\\bl_\\be_\\bs.\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     Currently haven can read and write logical, integer, numeric,\\n     character and factors. See 'labelled_spss' for how labelled\\n     variables in SPSS are handled in R. 'read_spss' is an alias for\\n     'read_sav'.\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n     read_sav(file, user_na = FALSE)\\n     \\n     read_por(file, user_na = FALSE)\\n     \\n     write_sav(data, path)\\n     \\n     read_spss(file, user_na = FALSE)\\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\n    file: Either a path to a file, a connection, or literal data\\n          (either a single string or a raw vector).\\n\\n          Files ending in '.gz', '.bz2', '.xz', or '.zip' will be\\n          automatically uncompressed. Files starting with 'http://',\\n          'https://', 'ftp://', or 'ftps://' will be automatically\\n          downloaded. Remote gz files can also be automatically\\n          downloaded and decompressed.\\n\\n          Literal data is most useful for examples and tests. It must\\n          contain at least one new line to be recognised as data\\n          (instead of a path).\\n\\n user_na: If 'TRUE' variables with user defined missing will be read\\n          into 'labelled_spss' objects. If 'FALSE', the default,\\n          user-defined missings will be converted to 'NA'.\\n\\n    data: Data frame to write.\\n\\n    path: Path to a file where the data will be written.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\n     A tibble, data frame variant with nice defaults.\\n\\n     Variable labels are stored in the \\\"label\\\" attribute of each\\n     variable.  It is not printed on the console, but the RStudio\\n     viewer will show it.\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     path <- system.file(\\\"examples\\\", \\\"iris.sav\\\", package = \\\"haven\\\")\\n     read_sav(path)\\n     \\n     tmp <- tempfile(fileext = \\\".sav\\\")\\n     write_sav(mtcars, tmp)\\n     read_sav(tmp)\\n     \\n\\n\",\"type\":1},{\"output\":\"read_dta                 package:haven                 R Documentation\\n\\n_\\bR_\\be_\\ba_\\bd _\\ba_\\bn_\\bd _\\bw_\\br_\\bi_\\bt_\\be _\\bS_\\bt_\\ba_\\bt_\\ba _\\bD_\\bT_\\bA _\\bf_\\bi_\\bl_\\be_\\bs.\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     Currently haven can read and write logical, integer, numeric,\\n     character and factors. See 'labelled' for how labelled variables\\n     in Stata are handled in R.\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n     read_dta(file, encoding = NULL)\\n     \\n     read_stata(file, encoding = NULL)\\n     \\n     write_dta(data, path, version = 14)\\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\n    file: Either a path to a file, a connection, or literal data\\n          (either a single string or a raw vector).\\n\\n          Files ending in '.gz', '.bz2', '.xz', or '.zip' will be\\n          automatically uncompressed. Files starting with 'http://',\\n          'https://', 'ftp://', or 'ftps://' will be automatically\\n          downloaded. Remote gz files can also be automatically\\n          downloaded and decompressed.\\n\\n          Literal data is most useful for examples and tests. It must\\n          contain at least one new line to be recognised as data\\n          (instead of a path).\\n\\nencoding: The character encoding used for the file. This defaults to\\n          the encoding specified in the file, or UTF-8. But older\\n          versions of Stata (13 and earlier) did not store the encoding\\n          used, and you'll need to specify manually. A commonly used\\n          value is \\\"windows-1252\\\".\\n\\n    data: Data frame to write.\\n\\n    path: Path to a file where the data will be written.\\n\\n version: File version to use. Supports versions 8-14.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\n     A tibble, data frame variant with nice defaults.\\n\\n     Variable labels are stored in the \\\"label\\\" attribute of each\\n     variable.  It is not printed on the console, but the RStudio\\n     viewer will show it.\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     path <- system.file(\\\"examples\\\", \\\"iris.dta\\\", package = \\\"haven\\\")\\n     read_dta(path)\\n     \\n     tmp <- tempfile(fileext = \\\".dta\\\")\\n     write_dta(mtcars, tmp)\\n     read_dta(tmp)\\n     read_stata(tmp)\\n     \\n\\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-09-23-Wrangling.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:11:09 2018 \\n\",\"type\":1},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:11:38 2018 \\n\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:11:41 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-09-29-Joining_Data_Sets.Rmd\\nLoading required package: grid\\nLoading required package: scales\\nRendering content/post/2016-09-30-BasicPlots.Rmd\\nLoading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"Rendering content/post/2016-10-04-WebGraphics.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:12:25 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-10-05-Themes_Facets.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:12:30 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-10-07-REstimation.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:13:28 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-10-07-REstimation2.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:13:33 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-10-13-HypothesisTesting.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:13:36 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-10-20-Correlation.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:13:39 2018 \\n\",\"type\":1},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:13:46 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2016-10-28-SimpleRegression.Rmd\\nLoading required package: grid\\nLoading required package: scales\\nLoading required package: bitops\\nLoading required package: nlme\\nThis is mgcv 1.8-23. For overview type 'help(\\\"mgcv-package\\\")'.\\n── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ dplyr::collapse()   masks nlme::collapse()\\n✖ tidyr::complete()   masks RCurl::complete()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n✖ dplyr::recode()     masks car::recode()\\n✖ dplyr::select()     masks MASS::select()\\n✖ purrr::some()       masks car::some()\\n\\nAttaching package: 'Rfit'\\n\\nThe following object is masked from 'package:car':\\n\\n    subsets\\n\\n\",\"type\":2},{\"output\":\"Rendering content/post/2016-11-11-MultipleRegression.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:02 2018 \\n\",\"type\":1},{\"output\":\"Loading required package: bitops\\n\",\"type\":2},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ tidyr::complete()   masks RCurl::complete()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"\\nAttaching package: 'GGally'\\n\\nThe following object is masked from 'package:dplyr':\\n\\n    nasa\\n\\n\",\"type\":2},{\"output\":\"\\nAttaching package: 'gridExtra'\\n\\nThe following object is masked from 'package:dplyr':\\n\\n    combine\\n\\n\",\"type\":2},{\"output\":\"SHA-1 hash of file is 050161a8c6c865eb18566324719c9079fc99674f\\n\",\"type\":2},{\"output\":\"Rendering content/post/2016-12-09-ANOVA_1factor.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:11 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n\",\"type\":2},{\"output\":\"✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\nLoading required package: Matrix\\n\",\"type\":2},{\"output\":\"\\nAttaching package: 'Matrix'\\n\\nThe following object is masked from 'package:tidyr':\\n\\n    expand\\n\\n\",\"type\":2},{\"output\":\"Loading required package: mvtnorm\\nLoading required package: survival\\n\",\"type\":2},{\"output\":\"Loading required package: TH.data\\nLoading required package: MASS\\n\\nAttaching package: 'MASS'\\n\\nThe following object is masked from 'package:dplyr':\\n\\n    select\\n\\n\\nAttaching package: 'TH.data'\\n\\nThe following object is masked from 'package:MASS':\\n\\n    geyser\\n\\n\",\"type\":2},{\"output\":\"Rendering content/post/2016-12-16-ANOVA_multifactor.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:17 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\nLoading required package: mvtnorm\\nLoading required package: survival\\n\",\"type\":2},{\"output\":\"Loading required package: TH.data\\nLoading required package: MASS\\n\\nAttaching package: 'MASS'\\n\\nThe following object is masked from 'package:dplyr':\\n\\n    select\\n\\n\\nAttaching package: 'TH.data'\\n\\nThe following object is masked from 'package:MASS':\\n\\n    geyser\\n\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-01-13-GettingtoKnowRAgain.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:21 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:26 2018 \\n\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:29 2018 \\n\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:29 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2017-01-20-Rmarkdowntutorial.Rmd\\nLoading required package: grid\\nLoading required package: scales\\nx is les than 5\\nWarning in message_function(10) : x greater than 6\\nRendering content/post/2017-02-03-EcologicalDetective1.Rmd\\nLoading required package: grid\\nLoading required package: scales\\nRendering content/post/2017-02-10-EcologicalDetective2.Rmd\\nLoading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-02-23-EcologicalDetective3.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:36 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Binomial                 package:stats                 R Documentation\\n\\n_\\bT_\\bh_\\be _\\bB_\\bi_\\bn_\\bo_\\bm_\\bi_\\ba_\\bl _\\bD_\\bi_\\bs_\\bt_\\br_\\bi_\\bb_\\bu_\\bt_\\bi_\\bo_\\bn\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     Density, distribution function, quantile function and random\\n     generation for the binomial distribution with parameters 'size'\\n     and 'prob'.\\n\\n     This is conventionally interpreted as the number of 'successes' in\\n     'size' trials.\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n     dbinom(x, size, prob, log = FALSE)\\n     pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE)\\n     qbinom(p, size, prob, lower.tail = TRUE, log.p = FALSE)\\n     rbinom(n, size, prob)\\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\n    x, q: vector of quantiles.\\n\\n       p: vector of probabilities.\\n\\n       n: number of observations. If 'length(n) > 1', the length is\\n          taken to be the number required.\\n\\n    size: number of trials (zero or more).\\n\\n    prob: probability of success on each trial.\\n\\nlog, log.p: logical; if TRUE, probabilities p are given as log(p).\\n\\nlower.tail: logical; if TRUE (default), probabilities are P[X <= x],\\n          otherwise, P[X > x].\\n\\n_\\bD_\\be_\\bt_\\ba_\\bi_\\bl_\\bs:\\n\\n     The binomial distribution with 'size' = n and 'prob' = p has\\n     density\\n\\n                       p(x) = choose(n, x) p^x (1-p)^(n-x)              \\n     \\n     for x = 0, ..., n.  Note that binomial _coefficients_ can be\\n     computed by 'choose' in R.\\n\\n     If an element of 'x' is not integer, the result of 'dbinom' is\\n     zero, with a warning.\\n\\n     p(x) is computed using Loader's algorithm, see the reference\\n     below.\\n\\n     The quantile is defined as the smallest value x such that F(x) >=\\n     p, where F is the distribution function.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\n     'dbinom' gives the density, 'pbinom' gives the distribution\\n     function, 'qbinom' gives the quantile function and 'rbinom'\\n     generates random deviates.\\n\\n     If 'size' is not an integer, 'NaN' is returned.\\n\\n     The length of the result is determined by 'n' for 'rbinom', and is\\n     the maximum of the lengths of the numerical arguments for the\\n     other functions.\\n\\n     The numerical arguments other than 'n' are recycled to the length\\n     of the result.  Only the first elements of the logical arguments\\n     are used.\\n\\n_\\bS_\\bo_\\bu_\\br_\\bc_\\be:\\n\\n     For 'dbinom' a saddle-point expansion is used: see\\n\\n     Catherine Loader (2000). _Fast and Accurate Computation of\\n     Binomial Probabilities_; available from <URL:\\n     http://www.herine.net/stat/software/dbinom.html>.\\n\\n     'pbinom' uses 'pbeta'.\\n\\n     'qbinom' uses the Cornish-Fisher Expansion to include a skewness\\n     correction to a normal approximation, followed by a search.\\n\\n     'rbinom' (for 'size < .Machine$integer.max') is based on\\n\\n     Kachitvichyanukul, V. and Schmeiser, B. W. (1988) Binomial random\\n     variate generation.  _Communications of the ACM_, *31*, 216-222.\\n\\n     For larger values it uses inversion.\\n\\n_\\bS_\\be_\\be _\\bA_\\bl_\\bs_\\bo:\\n\\n     Distributions for other standard distributions, including\\n     'dnbinom' for the negative binomial, and 'dpois' for the Poisson\\n     distribution.\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     require(graphics)\\n     # Compute P(45 < X < 55) for X Binomial(100,0.5)\\n     sum(dbinom(46:54, 100, 0.5))\\n     \\n     ## Using \\\"log = TRUE\\\" for an extended range :\\n     n <- 2000\\n     k <- seq(0, n, by = 20)\\n     plot (k, dbinom(k, n, pi/10, log = TRUE), type = \\\"l\\\", ylab = \\\"log density\\\",\\n           main = \\\"dbinom(*, log=TRUE) is better than  log(dbinom(*))\\\")\\n     lines(k, log(dbinom(k, n, pi/10)), col = \\\"red\\\", lwd = 2)\\n     ## extreme points are omitted since dbinom gives 0.\\n     mtext(\\\"dbinom(k, log=TRUE)\\\", adj = 0)\\n     mtext(\\\"extended range\\\", adj = 0, line = -1, font = 4)\\n     mtext(\\\"log(dbinom(k))\\\", col = \\\"red\\\", adj = 1)\\n     \\n\\n\",\"type\":1},{\"output\":\"Rendering content/post/2017-03-03-SixSidedDieRolls.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:42 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2017-03-10-EcologicalDetective5.Rmd\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:52 2018 \\n\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:14:58 2018 \\n\",\"type\":1},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\nRendering content/post/2017-03-17-EcologicalDetective6.Rmd\\nLoading required package: grid\\nLoading required package: scales\\n── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-03-30-IncidentalCatch.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:15:07 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-04-14-SumofSquares.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:15:11 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-04-28-Likelihood.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:15:46 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-08-25-IntrotoR.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:15:49 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Parsed with column specification:\\ncols(\\n  record_id = col_integer(),\\n  month = col_integer(),\\n  day = col_integer(),\\n  year = col_integer(),\\n  plot_id = col_integer(),\\n  species_id = col_character(),\\n  sex = col_character(),\\n  hindfoot_length = col_integer(),\\n  weight = col_integer(),\\n  genus = col_character(),\\n  species = col_character(),\\n  taxa = col_character(),\\n  plot_type = col_character()\\n)\\n\",\"type\":2},{\"output\":\"mean                   package:base                    R Documentation\\n\\n_\\bA_\\br_\\bi_\\bt_\\bh_\\bm_\\be_\\bt_\\bi_\\bc _\\bM_\\be_\\ba_\\bn\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     Generic function for the (trimmed) arithmetic mean.\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n     mean(x, ...)\\n     \\n     ## Default S3 method:\\n     mean(x, trim = 0, na.rm = FALSE, ...)\\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\n       x: An R object.  Currently there are methods for numeric/logical\\n          vectors and date, date-time and time interval objects.\\n          Complex vectors are allowed for 'trim = 0', only.\\n\\n    trim: the fraction (0 to 0.5) of observations to be trimmed from\\n          each end of 'x' before the mean is computed.  Values of trim\\n          outside that range are taken as the nearest endpoint.\\n\\n   na.rm: a logical value indicating whether 'NA' values should be\\n          stripped before the computation proceeds.\\n\\n     ...: further arguments passed to or from other methods.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\n     If 'trim' is zero (the default), the arithmetic mean of the values\\n     in 'x' is computed, as a numeric or complex vector of length one.\\n     If 'x' is not logical (coerced to numeric), numeric (including\\n     integer) or complex, 'NA_real_' is returned, with a warning.\\n\\n     If 'trim' is non-zero, a symmetrically trimmed mean is computed\\n     with a fraction of 'trim' observations deleted from each end\\n     before the mean is computed.\\n\\n_\\bR_\\be_\\bf_\\be_\\br_\\be_\\bn_\\bc_\\be_\\bs:\\n\\n     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\\n     Language_.  Wadsworth & Brooks/Cole.\\n\\n_\\bS_\\be_\\be _\\bA_\\bl_\\bs_\\bo:\\n\\n     'weighted.mean', 'mean.POSIXct', 'colMeans' for row and column\\n     means.\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     x <- c(0:10, 50)\\n     xm <- mean(x)\\n     c(xm, mean(x, trim = 0.10))\\n     \\n\\n\",\"type\":1},{\"output\":\"Rendering content/post/2017-09-01-IntrotoDataWrangling.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:15:55 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n\",\"type\":2},{\"output\":\"✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Parsed with column specification:\\ncols(\\n  record_id = col_integer(),\\n  month = col_integer(),\\n  day = col_integer(),\\n  year = col_integer(),\\n  plot_id = col_integer(),\\n  species_id = col_character(),\\n  sex = col_character(),\\n  hindfoot_length = col_integer(),\\n  weight = col_integer(),\\n  genus = col_character(),\\n  species = col_character(),\\n  taxa = col_character(),\\n  plot_type = col_character()\\n)\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-09-08-Introtoggplot2.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:16:00 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/2017-09-15-Introtomultivariate.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:16:00 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Parsed with column specification:\\ncols(\\n  Site = col_integer(),\\n  Tsuga.canadensis = col_double()\\n)\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-09-29-Clustering_1.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:16:05 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Loading required package: permute\\nLoading required package: lattice\\n\",\"type\":2},{\"output\":\"This is vegan 2.4-6\\n\",\"type\":2},{\"output\":\"Welcome! Related Books: `Practical Guide To Cluster Analysis in R` at https://goo.gl/13EFCZ\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-09-29-Dissimilarites.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:16:10 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\nLoading required package: permute\\nLoading required package: lattice\\n\",\"type\":2},{\"output\":\"This is vegan 2.4-6\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-10-06-Clustering_2.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:16:14 2018 \\n\",\"type\":1},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\nLoading required package: permute\\nLoading required package: lattice\\n\",\"type\":2},{\"output\":\"This is vegan 2.4-6\\nWelcome! Related Books: `Practical Guide To Cluster Analysis in R` at https://goo.gl/13EFCZ\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-10-13-LatentVariables_1.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:16:27 2018 \\n\",\"type\":1},{\"output\":\"\\nAttaching package: 'psych'\\n\\nThe following objects are masked from 'package:scales':\\n\\n    alpha, rescale\\n\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-10-20-LatentVariables_2.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:16:32 2018 \\n\",\"type\":1},{\"output\":\"\\nAttaching package: 'psych'\\n\\nThe following objects are masked from 'package:scales':\\n\\n    alpha, rescale\\n\\nLoading required package: ggplot2\\n\\nAttaching package: 'ggplot2'\\n\\nThe following objects are masked from 'package:psych':\\n\\n    %+%, alpha\\n\\n\\nAttaching package: 'polycor'\\n\\nThe following object is masked from 'package:psych':\\n\\n    polyserial\\n\\nLoading required package: scatterplot3d\\nLoading required package: MASS\\n── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ tibble  1.4.2     ✔ purrr   0.2.4\\n✔ tidyr   0.8.0     ✔ dplyr   0.7.4\\n✔ readr   1.1.1     ✔ stringr 1.3.0\\n✔ tibble  1.4.2     ✔ forcats 0.3.0\\n── Conflicts ─────── tidyverse_conflicts() ──\\n✖ ggplot2::%+%()      masks psych::%+%()\\n✖ ggplot2::alpha()    masks psych::alpha(), scales::alpha()\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ dplyr::combine()    masks gridExtra::combine()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n✖ dplyr::select()     masks MASS::select()\\n\",\"type\":2},{\"output\":\"Joining, by = \\\"indicator\\\"\\n\",\"type\":2},{\"output\":\"Error in factanal(~ags1 + ags2 + ags3 + ags4 + ags5 + ags6 + ags7 + ags8 +  : \\n  factor analysis applies only to numerical variables\\n\",\"type\":2},{\"output\":\"Warning in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate,  :\\n   A loading greater than abs(1) was detected.  Examine the loadings carefully.\\n\",\"type\":2},{\"output\":\"Rendering content/post/2017-11-09-LatentVariables_3.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:16:54 2018 \\n\",\"type\":1},{\"output\":\"Loading required package: scatterplot3d\\nLoading required package: MASS\\nLoading required package: e1071\\nLoading required package: coda\\n\",\"type\":2},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ dplyr::combine()    masks gridExtra::combine()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n✖ dplyr::select()     masks MASS::select()\\n\",\"type\":2},{\"output\":\"poLCA.entropy              package:poLCA               R Documentation\\n\\n_\\bE_\\bn_\\bt_\\br_\\bo_\\bp_\\by _\\bo_\\bf _\\ba _\\bf_\\bi_\\bt_\\bt_\\be_\\bd _\\bl_\\ba_\\bt_\\be_\\bn_\\bt _\\bc_\\bl_\\ba_\\bs_\\bs _\\bm_\\bo_\\bd_\\be_\\bl\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     Calculates the entropy of a cross-classification table produced as\\n     a density estimate using a latent class model.\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n      poLCA.entropy(lc) \\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\n      lc: A model object estimated using the 'poLCA' function.\\n\\n_\\bD_\\be_\\bt_\\ba_\\bi_\\bl_\\bs:\\n\\n     Entropy is a measure of dispersion (or concentration) in a\\n     probability mass function. For multivariate categorical data it is\\n     calculated\\n\\n                           H = -sum_c p_c log(p_c)                      \\n     \\n     where p_c is the share of the probability in the _c_th cell of the\\n     cross-classification table.  A fitted latent class model produces\\n     a smoothed density estimate of the underlying distribution of cell\\n     percentages in the multi-way table of the manifest variables.\\n     This function calculates the entropy of that estimated probability\\n     mass function.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\n     A number taking a minumum value of 0 (representing complete\\n     concentration of probability on one cell) and a maximum value\\n     equal to the logarithm of the total number of cells in the fitted\\n     cross-classfication table (representing complete dispersion, or\\n     equal probability for outcomes across every cell).\\n\\n_\\bS_\\be_\\be _\\bA_\\bl_\\bs_\\bo:\\n\\n     'poLCA'\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     data(carcinoma)\\n     f <- cbind(A,B,C,D,E,F,G)~1\\n     lca2 <- poLCA(f,carcinoma,nclass=2) # log-likelihood: -317.2568\\n     lca3 <- poLCA(f,carcinoma,nclass=3) # log-likelihood: -293.705\\n     lca4 <- poLCA(f,carcinoma,nclass=4,nrep=10,maxiter=5000) # log-likelihood: -289.2858 \\n     \\n     # Maximum entropy (if all cases equally dispersed)\\n     log(prod(sapply(lca2$probs,ncol)))\\n     \\n     # Sample entropy (\\\"plug-in\\\" estimator, or MLE)\\n     p.hat <- lca2$predcell$observed/lca2$N\\n     H.hat <- -sum(p.hat * log(p.hat))\\n     H.hat   # 2.42\\n     \\n     # Entropy of fitted latent class models\\n     poLCA.entropy(lca2)\\n     poLCA.entropy(lca3)\\n     poLCA.entropy(lca4)\\n     \\n\\n\",\"type\":1},{\"output\":\"Rendering content/post/2017-11-17-Differencesbetweengroups.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:17:59 2018 \\n\",\"type\":1},{\"output\":\"Loading required package: permute\\nLoading required package: lattice\\n\",\"type\":2},{\"output\":\"This is vegan 2.4-6\\n\",\"type\":2},{\"output\":\"── Attaching packages ──── tidyverse 1.2.1 ──\\n✔ ggplot2 2.2.1     ✔ purrr   0.2.4\\n✔ tibble  1.4.2     ✔ dplyr   0.7.4\\n✔ tidyr   0.8.0     ✔ stringr 1.3.0\\n✔ readr   1.1.1     ✔ forcats 0.3.0\\n\",\"type\":2},{\"output\":\"── Conflicts ─────── tidyverse_conflicts() ──\\n✖ readr::col_factor() masks scales::col_factor()\\n✖ dplyr::combine()    masks gridExtra::combine()\\n✖ purrr::discard()    masks scales::discard()\\n✖ dplyr::filter()     masks stats::filter()\\n✖ dplyr::lag()        masks stats::lag()\\n\",\"type\":2},{\"output\":\"Rendering content/post/2018-02-23-AgeCohort.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:18:06 2018 \\n\",\"type\":1},{\"output\":\"apc.data.list               package:apc                R Documentation\\n\\n_\\bA_\\br_\\br_\\ba_\\bn_\\bg_\\be _\\bd_\\ba_\\bt_\\ba _\\ba_\\bs _\\ba_\\bn _\\ba_\\bp_\\bc._\\bd_\\ba_\\bt_\\ba._\\bl_\\bi_\\bs_\\bt\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     This is step 1 of the apc analysis.\\n\\n     The apc package is aimed at range of data types.  This analysis\\n     and labelling of parameters depends on the choice data type.  In\\n     order to keep track of this choice the data first has to be\\n     arranged as an apc.data.list.  The function purpose of this\\n     function is to aid the user in constructing a list with the right\\n     information.\\n\\n     Age period cohort analysis is used in two situations.  A\\n     dose-response situation, where both doses (exposure, risk set,\\n     cases) and responses (counts of deaths, outcomes) are available.\\n     And a response situation where only a response is available.  If\\n     the aim is to directly model mortality ratios (counts of death\\n     divided by exposure) this will be thought of a response\\n\\n     The 'apc.data.list' gives sufficient information for the further\\n     analysis. It is sufficient to store this information. It has 2\\n     obligatory arguments, which are a response matrix and a character\\n     indicating the data format. It also has some further optional\\n     arguments, which have certain default values.  Some times it may\\n     be convenient to add further arguments to the 'apc.data.list'.\\n     This will not affect the apc analysis.\\n\\n     'apc.data.list' generates default row and column names for the\\n     response and dose matrices when these are not provided by the\\n     user.\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n     apc.data.list(response, data.format, dose=NULL,\\n                                             age1=NULL, per1=NULL, coh1=NULL, unit=NULL,\\n                                             per.zero=NULL, per.max=NULL,\\n                                             time.adjust=NULL, label=NULL,\\n                                             n.decimal=NULL)\\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\nresponse: matrix (or vector).  Numbers of responses.  It should have a\\n          format matching 'data.format'.  Time should be increasing\\n          with the row/column index of the matrix.  For instance,\\n          consider a 10x5 matrix in \\\"AP\\\" format: Then the row index is\\n          for age, and it should be increasing in age. Thus, higher\\n          ages are further down the rows of the matrix.  In the same\\n          way, the column index is for period.\\n\\ndata.format: character.  The following options are implemented:\\n\\n          \\\"AC\\\" has age/cohort as increasing row/column index.\\n\\n          \\\"AP\\\" has age/period as increasing row/column index.\\n\\n          \\\"CA\\\" has cohort/age as increasing row/column index.\\n\\n          \\\"CL\\\" has cohort/age as increasing row/column index,\\n              triangular.\\n\\n          \\\"CP\\\" has cohort/period as increasing row/column index.\\n\\n          \\\"PA\\\" has period/age as increasing row/column index.\\n\\n          \\\"PC\\\" has period/cohort as increasing row/column index.\\n\\n          \\\"trapezoid\\\" has age/period as increasing row/column index,\\n              period-diagonals are NA for period <= per.zero and\\n              >per.zero+per.max.\\n\\n    dose: _Optional_. matrix or NULL.  Numbers of doses.  It should\\n          have same format as 'response'.\\n\\n    age1: _Optional_. Numeric or NULL.  Time label for youngest age\\n          group.  Used if 'data.format' is \\\"AC\\\", \\\"AP\\\", \\\"CA\\\", \\\"CL\\\",\\n          \\\"PA\\\", \\\"trapezoid\\\". If NULL default is 1.\\n\\n    per1: _Optional_. Numeric or NULL.  Time label for oldest period\\n          group.  Used if 'data.format' is \\\"AP\\\", \\\"CP\\\", \\\"PA\\\", \\\"PC\\\". If\\n          NULL default is 1.\\n\\n    coh1: _Optional_. Numeric or NULL.  Time label for youngest age\\n          group.  Used if 'data.format' is \\\"AC\\\", \\\"CA\\\", \\\"CL\\\",\\n          \\\"CL.vector.by.row\\\", \\\"CP\\\", \\\"PC\\\", \\\"trapezoid\\\". If NULL default\\n          is 1.\\n\\n    unit: _Optional_. Numeric or NULL.  Common time steps for age,\\n          period and cohort.  For quarterly data use '1/4'.  For\\n          monthly data use '1/12'. If NULL default is 1.\\n\\nper.zero: _Optional_. Numeric or NULL.  Needed if data format is\\n          \\\"trapezoid\\\".\\n\\n per.max: _Optional_. Numeric or NULL.  Needed if data format is\\n          \\\"trapezoid\\\".\\n\\ntime.adjust: _Optional_. Numeric.  Time labels are based on two of\\n          age1, per1 and coh1.  The third time label is computed\\n          according to the formula age1+coh1=per1+time.adjust.  Default\\n          is 0.  If age1=coh=1 it is natural to choose time.adjust=1.\\n\\n   label: _Optional_. Character.  Useful when working with multiple\\n          data sets. Some internal functions use the first three\\n          characters of the label for identification of the two\\n          datasets.\\n\\nn.decimal: _Optional_.  Numeric or NULL.  The labels for parameters\\n          involves a date. This is found by converting a number into a\\n          character.  If the value is set to 'd' package uses\\n          'sprintf'. If the value is set to 'NULL' and 'unit==1/4' for\\n          quarterly data or 'unit==1/12' for monthly data or\\n          '1/20<=unit && unit<1' then package uses 'sprintf'. If the\\n          value is set to 'NULL' and '1/20>unit || unit>=1' then\\n          package uses 'as.character', which looks nice for integers,\\n          but can be messy otherwise.\\n\\n_\\bD_\\be_\\bt_\\ba_\\bi_\\bl_\\bs:\\n\\n     If the user does not set values for any of 'age1', 'per1', 'coh1',\\n     'unit' then the value is set to 'unit'.\\n\\n     The user can set values of 'age1', 'per1', 'coh1' that are\\n     incongruent.  The functions only use two these that are relevant\\n     for the chosen 'data.format'.  Example: the 'data.format' may be\\n     '\\\"AC\\\"' and the user sets 'age1', 'per1', but 'age1', 'coh1' are\\n     relevant for this data format. The 'apc.data.list' then sets\\n     'coh1=unit', by default, while ignoring the value for 'per1'.\\n     Other commands such as 'apc.data.list.subset' or 'apc.fit.table',\\n     will internally, as default option, call the function\\n     'apc.get.index'. That function will, in this example, set 'per1'\\n     according to the values of 'age1' and 'coh1'.\\n\\n     If the user does not set a value for 'time.adjust' this is set\\n     equal to 'unit' when the user does not specify at least two\\n     'age1', 'per1', 'coh1'. Otherwise it is set to 0. The former\\n     choice matches the values in the theory papers, where indices\\n     count 1,2,... to follow standard notation for row/column indices\\n     for matrices, so that age+coh=per+unit. The latter choice seeks to\\n     match a real time scale the user sets according to age+coh=per.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\nresponse: matrix (or vector).  Numbers of responses.\\n\\n    dose: matrix (or NULL).  Numbers of doses.\\n\\ndata.format: character.\\n\\n    age1: Numeric. Default is NULL.\\n\\n    per1: Numeric. Default is NULL.\\n\\n    coh1: Numeric. Default is NULL.\\n\\n    unit: Numeric.  Default is NULL. For monthly data one use\\n          'unit=1/12'.\\n\\nper.zero: Numeric.  If data.format is not \\\"trapezoid\\\" the value is\\n          NULL. If data.format is \\\"trapezoid\\\" the coordinate system is\\n          in age-cohort format and this value counts how many periods\\n          are cut off. The default is 'per.zero=0'.\\n\\n per.max: Numeric.  If data.format is not \\\"trapezoid\\\" the value is\\n          NULL. If data.format is \\\"trapezoid\\\" the coordinate system is\\n          in age-cohort format and this value counts how many periods\\n          are included in the data array.  The default is\\n          'per.max=nrow(response)+ncol(response)-1-per.zero'.\\n\\ntime.adjust: Numeric.  Default is NULL.\\n\\n   label: Character. Default of NULL.\\n\\nn.decimal: Numeric or NULL.\\n\\n_\\bA_\\bu_\\bt_\\bh_\\bo_\\br(_\\bs):\\n\\n     Bent Nielsen <bent.nielsen@nuffield.ox.ac.uk> 17 Nov 2016\\n\\n_\\bR_\\be_\\bf_\\be_\\br_\\be_\\bn_\\bc_\\be_\\bs:\\n\\n     Kuang, D., Nielsen, B. and Nielsen, J.P. (2008a) Identification of\\n     the age-period-cohort model and the extended chain ladder model.\\n     Biometrika 95, 979-986. _Download_: Article; Earlier version\\n     Nuffield DP.\\n\\n     Nielsen, B. (2014) Deviance analysis of age-period-cohort models.\\n     _Download_: Nuffield DP.\\n\\n     Nielsen, B. (2015) apc: An R package for age-period-cohort\\n     analysis. _R Journal_ 7, 52-64. _Download_: Open access.\\n\\n_\\bS_\\be_\\be _\\bA_\\bl_\\bs_\\bo:\\n\\n     The below example shows how the 'data.Japanese.breast.cancer'\\n     data.list was generated. Other provided data sets include\\n     'data.asbestos' 'data.Belgian.lung.cancer'\\n     'data.Italian.bladder.cancer'.\\n\\n     A subset of the data can be selected using 'apc.data.list.subset'.\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     ###############\\n     #       Artificial data\\n     #       (1) Generate a 5x7 matrix and make arbitrary decisions for rest\\n     \\n     response <- matrix(data=seq(1:35),nrow=5,ncol=7)\\n     data.list       <- apc.data.list(response=response,data.format=\\\"AP\\\",\\n                                             age1=25,per1=1955,coh1=NULL,unit=5,\\n                                             per.zero=NULL,per.max=NULL)\\n     data.list\\n     \\n     #       (2) Chain Ladder data\\n     \\n     k                       <- 5\\n     v.response      <- seq(1:(k*(k+1)/2))\\n     data.list       <- apc.data.list(response=vector.2.triangle(v.response,k),\\n                                                             data.format=\\\"CL.vector.by.row\\\",age1=2001)\\n     data.list\\n     \\n     ###############\\n     #       Japanese breast cancer\\n     #       This is the code used to generate the data.Japanese.breast.cancer\\n     v.rates         <- c( 0.44, 0.38, 0.46, 0.55, 0.68,\\n                                       1.69, 1.69, 1.75, 2.31, 2.52,\\n                                       4.01, 3.90, 4.11, 4.44, 4.80,\\n                                       6.59, 6.57, 6.81, 7.79, 8.27,\\n                                       8.51, 9.61, 9.96,11.68,12.51,\\n                                      10.49,10.80,12.36,14.59,16.56,\\n                                      11.36,11.51,12.98,14.97,17.79,\\n                                      12.03,10.67,12.67,14.46,16.42,\\n                                      12.55,12.03,12.10,13.81,16.46,\\n                                      15.81,13.87,12.65,14.00,15.60,\\n                                      17.97,15.62,15.83,15.71,16.52)\\n     v.cases         <- c(   88,   78,  101,  127,  179,\\n                                        299,  330,  363,  509,  588,\\n                                        596,  680,  798,  923, 1056,\\n                                        874,  962, 1171, 1497, 1716,\\n                                       1022, 1247, 1429, 1987, 2398,\\n                                       1035, 1258, 1560, 2079, 2794,\\n                                        970, 1087, 1446, 1828, 2465,\\n                                        820,  861, 1126, 1549, 1962,\\n                                        678,  738,  878, 1140, 1683,\\n                                        640,  628,  656,  900, 1162,\\n                                        497,  463,  536,  644,  865)                          \\n     #       see also example below for generating labels\\n     \\n     rates   <- matrix(data=v.rates,nrow=11, ncol=5,byrow=TRUE)\\n     cases   <- matrix(data=v.cases,nrow=11, ncol=5,byrow=TRUE)\\n     \\n     #       A data list is now constructed as follows\\n     #       note that list entry rates is redundant,\\n     #       but included since it represents original data\\n     \\n     data.Japanese.breast.cancer     <- apc.data.list(response=cases,\\n                             dose=cases/rates,data.format=\\\"AP\\\",\\n                             age1=25,per1=1955,coh1=NULL,unit=5,\\n                             per.zero=NULL,per.max=NULL,time.adjust=0,\\n                             label=\\\"Japanese breast cancer\\\")\\n     \\n     #       or when exploiting the default values\\n     \\n     data.Japanese.breast.cancer     <- apc.data.list(response=cases,\\n                             dose=cases/rates,data.format=\\\"AP\\\",\\n                             age1=25,per1=1955,unit=5,\\n                             label=\\\"Japanese breast cancer\\\")\\n     \\n     ###################################################\\n     #       Code for generating labels\\n     \\n     row.names <- paste(as.character(seq(25,75,by=5)),\\\"-\\\",as.character(seq(29,79,by=5)),sep=\\\"\\\")\\n     col.names <- paste(as.character(seq(1955,1975,by=5)),\\\"-\\\",as.character(seq(1959,1979,by=5)),sep=\\\"\\\")\\n     \\n\\n\",\"type\":1},{\"output\":\"apc.fit.model               package:apc                R Documentation\\n\\n_\\bF_\\bi_\\bt_\\bs _\\ba_\\bn _\\ba_\\bg_\\be _\\bp_\\be_\\br_\\bi_\\bo_\\bd _\\bc_\\bo_\\bh_\\bo_\\br_\\bt _\\bm_\\bo_\\bd_\\be_\\bl\\n\\n_\\bD_\\be_\\bs_\\bc_\\br_\\bi_\\bp_\\bt_\\bi_\\bo_\\bn:\\n\\n     'apc.fit.model' fits the age period cohort model as a Generalized\\n     Linear Model using 'glm.fit'. The model is parametrised in terms\\n     of the canonical parameter introduced by Kuang, Nielsen and\\n     Nielsen (2008), see also the implementation in Martinez Miranda,\\n     Nielsen and Nielsen (2015). This parametrisation has a number of\\n     advantages: it is freely varying, it is the canonical parameter of\\n     a regular exponential family, and it is invariant to extentions of\\n     the data matrix.\\n\\n     'apc.fit.model' can be be used for all three age period cohort\\n     factors, or for submodels with fewer of these factors.\\n\\n     'apc.fit.model' can be used either for mortality rates through a\\n     dose-response model or for mortality counts through a pure\\n     response model without doses/exposures.\\n\\n     The GLM families include Poisson regressions (with log link) and\\n     Normal/Gaussian least squares regressions.\\n\\n     apc.fit.table produces a deviance table for 15 combinations of the\\n     three factors and linear trends: \\\"APC\\\", \\\"AP\\\", \\\"AC\\\", \\\"PC\\\", \\\"Ad\\\",\\n     \\\"Pd\\\", \\\"Cd\\\", \\\"A\\\", \\\"P\\\", \\\"C\\\", \\\"t\\\", \\\"tA\\\", \\\"tP\\\", \\\"tC\\\", \\\"1\\\".\\n\\n_\\bU_\\bs_\\ba_\\bg_\\be:\\n\\n     apc.fit.model(apc.data.list,model.family,model.design,apc.index=NULL)\\n     apc.fit.table(apc.data.list,model.family,model.design.reference=\\\"APC\\\",apc.index=NULL)\\n     \\n_\\bA_\\br_\\bg_\\bu_\\bm_\\be_\\bn_\\bt_\\bs:\\n\\napc.data.list: List. See 'apc.data.list' for a description of the\\n          format.\\n\\nmodel.family: Character.  The following options are implemented.  These\\n          are used internally when calling 'glm.fit'.\\n\\n          \\\"poisson.response\\\" This sets family=poisson(link=\\\"log\\\"). Only\\n              responses are used.  Inference is done in a multinomial\\n              model, conditioning on the overall level as documented in\\n              Martinez Miranda, Nielsen and Nielsen (2015).\\n\\n          \\\"od.poisson.response\\\" This sets\\n              family=quasipoisson(link=\\\"log\\\") in the estimation step,\\n              but then reverts to family=poisson(link=\\\"log\\\") when\\n              computing standard errors, which are then corrected.\\n              Only responses are used.  Inference is done in an\\n              over-dispersed Poisson model as documented in Harnau and\\n              Nielsen (2016).  Note that limit distributions are t and\\n              F not normal and chi2.\\n\\n          \\\"poisson.dose.response\\\" This sets family=poisson(link=\\\"log\\\").\\n              Doses are used as offset.\\n\\n          \\\"binomial.dose.response\\\" This sets\\n              family=binomial(link=\\\"logit\\\") and gives a logistic\\n              regression.\\n\\n          \\\"gaussian.rates\\\" This sets family=gaussian(link=\\\"identity\\\").\\n              The dependent variable is the mortality rates, which are\\n              computed as response/dose.\\n\\n          \\\"gaussian.response\\\" This sets\\n              family=gaussian(link=\\\"identity\\\").  Only responses are\\n              used.  The dependent variable is the responses.\\n\\nmodel.design: Character.  This indicates the design choice.  The\\n          following options are possible.\\n\\n          \\\"APC\\\" Age-period-cohort model.\\n\\n          \\\"AP\\\" Age-period model. Nested in \\\"APC\\\"\\n\\n          \\\"AC\\\" Age-cohort model. Nested in \\\"APC\\\"\\n\\n          \\\"PC\\\" Period-cohort model. Nested in \\\"APC\\\"\\n\\n          \\\"Ad\\\" Age-trend model, including age effect and two linear\\n              trends. Nested in \\\"AP\\\", \\\"AC\\\".\\n\\n          \\\"Pd\\\" Period-trend model, including period effect and two\\n              linear trends. Nested in \\\"AP\\\", \\\"PC\\\".\\n\\n          \\\"Cd\\\" Cohort-trend model, including cohort effect and two\\n              linear trends. Nested in \\\"AC\\\", \\\"PC\\\".\\n\\n          \\\"A\\\" Age model. Nested in \\\"Ad\\\".\\n\\n          \\\"P\\\" Period model. Nested in \\\"Pd\\\".\\n\\n          \\\"C\\\" Cohort model. Nested in \\\"Cd\\\".\\n\\n          \\\"t\\\" Trend model, with two linear trends. Nested in \\\"Ad\\\",\\n              \\\"Pd\\\", \\\"Cd\\\".\\n\\n          \\\"tA\\\" Single trend model in age index. Nested in \\\"A\\\", \\\"t\\\".\\n\\n          \\\"tP\\\" Single trend model in period index. Nested in \\\"P\\\", \\\"t\\\".\\n\\n          \\\"tC\\\" Single trend model in cohort index. Nested in \\\"C\\\", \\\"t\\\".\\n\\n          \\\"1\\\" Constant model. Nested in \\\"tA\\\", \\\"tP\\\", \\\"tC\\\".\\n\\nmodel.design.reference: Character.  This indicates the reference design\\n          choice for the deviance table. Choices are\\n          \\\"APC\\\",\\\"AP\\\",\\\"AC\\\",\\\"PC\\\",\\\"Ad\\\",\\\"Pd\\\",\\\"Cd\\\",\\\"A\\\",\\\"P\\\",\\\"C\\\",\\\"t\\\". Default\\n          is \\\"APC\\\".\\n\\napc.index: _Optional_. List. See 'apc.get.index' for a description of\\n          the format.  If not provided this is computed internally.  If\\n          'apc.fit.model' is used in a simulation study computational\\n          effort can be saved when using this option.\\n\\n_\\bV_\\ba_\\bl_\\bu_\\be:\\n\\n     _apc.fit.table_ produces a deviance table.  There are 15 rows\\n     corresponding to all possible design choices.  The columns are as\\n     follows.\\n\\n\\\"-2logL\\\": -2 log Likelihood up to some constant.  If the model family\\n          is Poisson or binomial (logistic) this is the same as the\\n          'glm' deviance: That is the difference in -2 log likelihood\\n          value between estimated model and the saturated model.  If\\n          the model family is Gaussian it is different from the\\n          traditional 'glm' deviance.  Here the -2 log likelihood value\\n          is measured in a model with unknown variance, which is the\\n          standard in regression analysis, whereas in the 'glm' package\\n          the deviance is the residual sum of squares, which can be\\n          interpreted as the -2 log likelihood value in a model with\\n          variance set to one.\\n\\n\\\"df.residual\\\": Degrees of freedom of residual: nrow x ncol -\\n          dim(parameter).  If the model.family=\\\"poisson.response\\\" the\\n          degrees of freedom is one lower.\\n\\n\\\"prob(>chi_sq)\\\": p-value of the deviance, -2logL. Left out in Gaussian\\n          case which has no saturated model\\n\\n\\\"LR vs APC\\\": the likelihood ratio statistic against the \\\"APC\\\" model.\\n\\n    \\\"df\\\": Degrees of freedom against the \\\"APC\\\" model.\\n\\n\\\"prob(>chi_sq)\\\": p-value of log likelihood ratio statistic.\\n\\n   \\\"aic\\\": Akaike's \\\"An Information Criterion\\\", minus twice the\\n          maximized log-likelihood plus twice the number of parameters\\n          upto a constant.  It is take directly from the 'glm'\\n          function.  For the \\\"poisson.dose.response\\\" and\\n          \\\"binomial.dose.response\\\" model families the dispersion is\\n          fixed at one and the number of parameters is the number of\\n          coefficients.  The \\\"poisson.response\\\" model is conditional on\\n          the level.  The number of parameters should therefore be\\n          adjusted by subtracting 2 to take this into account to get\\n          the proper AIC. However, in practice this does not matter,\\n          since we are only interested in relative effects.  For the\\n          \\\"gaussian.response\\\" and \\\"gaussian.dose.response\\\" model\\n          families the dispersion is estimated from the residual\\n          deviance.\\n\\n     \\\"F\\\": Only for \\\"od.poisson.response\\\". F statistic: Ratio of\\n          deviance for submodel divided by degrees of freedom to\\n          deviance of apc model divided by degrees of freedom.\\n\\n\\\"prof(>F)\\\": Only for \\\"od.poisson.response\\\". F statistic: with degrees\\n          of freedom given by differences between sub-model and apc\\n          model and between apc model and saturated model.\\n     _apc.fit.model_ returns a list. The entries are as follows.\\n\\n     fit: List. Values from 'glm.fit'.\\n\\napc.index: List. Values from 'apc.get.index'.\\n\\ncoefficients.canonical: Matrix.  For each coordinate of the canonical\\n          parameters is reported coefficient, standard deviation,\\n          z-value, which is the ratio of those, and asymptotically\\n          normal p-values.  Note, for \\\"od.poisson.response\\\" the\\n          reported standard errors corrected by the deviance and\\n          p-values are asymptotically t distributed, see Harnau and\\n          Nielsen (2016).\\n\\ncovariance.canonical : Matrix.  Estimated covariance matrix for\\n          canonical parameters.\\n\\nslopes : Vector.  Length three.  The design matrix found by\\n          'apc.get.design.collinear' has age, period, and cohort linear\\n          trends. 'slopes' indicates which of these are actually used\\n          in estimation.\\n\\ndifdif : Vector.  Length three.  The design matrix found by\\n          'apc.get.design.collinear' has age, period, and cohort double\\n          differences. 'slopes' indicates which of these are actually\\n          used in estimation.\\n\\nindex.age : Vector.  Indices for age double difference parameters\\n          within 'coefficients.canonical'.  NULL if age double\\n          differences are not estimated.\\n\\nindex.per : Vector.  Indices for period double difference parameters\\n          within 'coefficients.canonical'.  NULL if period double\\n          differences are not estimated.\\n\\nindex.coh : Vector.  Indices for cohort double difference parameters\\n          within 'coefficients.canonical'.  NULL if cohort double\\n          differences are not estimated.\\n\\ndates : Vector.  Indicates the dates for the double difference\\n          parameters within 'coefficients.canonical'.\\n\\nmodel.family : Character. Argument.\\n\\nmodel.design : Character. Argument.\\n\\nRSS : Numeric.  Residual sum of squares.  NULL for non-gaussian\\n          families.\\n\\nsigma2 : Numeric.  Maximum likelihood estimator for variance: RSS/n.\\n          NULL for non-gaussian families.\\n\\ns2 : Numeric.  Least squares estimator for variance: RSS/df.  NULL for\\n          non-gaussian families.\\n\\nn.decimal : Numeric.  From 'apc.data.list'.\\n\\npredictors : Vector. Design*Estimates.  Same as the 'glm.fit' value\\n          'linear.predictors' when there is no offset.\\n\\n_\\bN_\\bo_\\bt_\\be:\\n\\n     For gaussian families _deviance_ is defined differently in 'apc'\\n     and 'glm'. Here it is -2 log likelihood.  In 'glm' it is RSS.\\n\\n     The values for 'apc.fit.model' include the 'apc.data.list' and the\\n     'apc.index' returned by 'apc.get.index'.\\n\\n     For the 'poisson.response' the inference is conditional on the\\n     level, see Martinez Miranda, Nielsen and Nielsen (2015). The\\n     'coefficients.canonical' computed by 'apc' are therefore different\\n     from the default 'coefficients' computed by 'glm'.\\n\\n     For the 'od.poisson.response' an asymptotic theory is used that\\n     mimics the conditioning for 'poisson.response'. The asymptotic\\n     distribution are, however, asymptotically t or F distributed, see\\n     Harnau and Nielsen (2016).\\n\\n     For 'coefficients' the 3rd and 4th columns have headings 't value'\\n     and 'Pr(>|t|)' for 'od.poisson.response' to indicate an asymptotic\\n     t theory and otherwise 'z value' and 'Pr(>|z|)' to indicate an\\n     asymptotic normal theory. The labels are inherited from 'glm.fit'.\\n\\n_\\bA_\\bu_\\bt_\\bh_\\bo_\\br(_\\bs):\\n\\n     Bent Nielsen <bent.nielsen@nuffield.ox.ac.uk> 26 Oct 2016 (27 Aug\\n     2014)\\n\\n_\\bR_\\be_\\bf_\\be_\\br_\\be_\\bn_\\bc_\\be_\\bs:\\n\\n     Harnau, J. and Nielsen, B. (2016) Asymptotic theory for\\n     over-dispersed age-period-cohort and extended chain ladder models.\\n     Mimeo.\\n\\n     Kuang, D., Nielsen, B. and Nielsen, J.P. (2008) Identification of\\n     the age-period-cohort model and the extended chain ladder model.\\n     Biometrika 95, 979-986. _Download_: Article; Earlier version\\n     Nuffield DP.\\n\\n     Martinez Miranda, M.D., Nielsen, B. and Nielsen, J.P. (2015)\\n     Inference and forecasting in the age-period-cohort model with\\n     unknown exposure with an application to mesothelioma mortality.\\n     _Journal of the Royal Statistical Society_ A 178, 29-55;\\n     _Download_: Earlier version Nuffield DP.\\n\\n_\\bS_\\be_\\be _\\bA_\\bl_\\bs_\\bo:\\n\\n     The fit is done using 'glm.fit'.\\n\\n     The examples below use Italian bladder cancer data, see\\n     'data.Italian.bladder.cancer' and Belgian lung cancer data, see\\n     'data.Belgian.lung.cancer'.\\n\\n     In example 3 the design matrix is called is called using\\n     'apc.get.design'.\\n\\n_\\bE_\\bx_\\ba_\\bm_\\bp_\\bl_\\be_\\bs:\\n\\n     #####################\\n     #       EXAMPLE 1 with Italian bladder cancer data\\n     \\n     data.list       <- data.Italian.bladder.cancer()        #       function gives data list\\n     apc.fit.table(data.list,\\\"poisson.dose.response\\\")\\n     \\n     #              -2logL df.residual prob(>chi_sq) LR.vs.APC df.vs.APC prob(>chi_sq)       aic\\n     #       APC    33.179          27         0.191        NA        NA            NA   487.624\\n     #       AP    512.514          40         0.000   479.335        13         0.000   940.958\\n     #       AC     39.390          30         0.117     6.211         3         0.102   487.835\\n     #       PC   1146.649          36         0.000  1113.470         9         0.000  1583.094\\n     #       Ad    518.543          43         0.000   485.364        16         0.000   940.988\\n     #       Pd   4041.373          49         0.000  4008.194        22         0.000  4451.818\\n     #       Cd   1155.629          39         0.000  1122.450        12         0.000  1586.074\\n     #       A    2223.800          44         0.000  2190.621        17         0.000  2644.245\\n     #       P   84323.944          50         0.000 84290.765        23         0.000 84732.389\\n     #       C   23794.205          40         0.000 23761.026        13         0.000 24222.650\\n     #       t    4052.906          52         0.000  4019.727        25         0.000  4457.351\\n     #       tA   5825.158          53         0.000  5791.979        26         0.000  6227.602\\n     #       tP  84325.758          53         0.000 84292.579        26         0.000 84728.203\\n     #       tC  33446.796          53         0.000 33413.617        26         0.000 33849.241\\n     #       1   87313.678          54         0.000 87280.499        27         0.000 87714.123\\n     #\\n     #       Table suggests that \\\"APC\\\" and \\\"AC\\\" fit equally well.  Try both\\n     \\n     fit.apc <- apc.fit.model(data.list,\\\"poisson.dose.response\\\",\\\"APC\\\")\\n     fit.ac  <- apc.fit.model(data.list,\\\"poisson.dose.response\\\",\\\"AC\\\")\\n     \\n     #       Compare the estimates: They are very similar\\n     \\n     fit.apc$coefficients.canonical\\n     fit.ac$coefficients.canonical\\n     \\n     #####################\\n     #       EXAMPLE 2 with Belgian lung cancer data\\n     #       This example illustrates how to find the linear predictors \\n     \\n     data.list       <- data.Belgian.lung.cancer()\\n     \\n     #       Get an APC fit\\n     \\n     fit.apc <- apc.fit.model(data.list,\\\"poisson.dose.response\\\",\\\"APC\\\")\\n     \\n     #       The linear predictor of the fit is a vector.\\n     #       But, we would like it in the same format as the data.\\n     #       Thus create matrix of same dimension as response data\\n     #       This can be done in two ways\\n     \\n     m.lp    <- data.list$response   #       using original information      \\n     m.lp    <- fit.apc$response             #       using information copied when fitting\\n     \\n     #       the fit object index.data is used to fill linear predictor in\\n     #       vector format into matrix format\\n     \\n     m.lp[fit.apc$index.data]        <-fit.apc$linear.predictors\\n     exp(m.lp)\\n     \\n     #####################\\n     #       EXAMPLE 3 with Belgian lung cancer data\\n     #       This example illustrates how apc.fit.model works.\\n     \\n     data.list       <- data.Belgian.lung.cancer()\\n     \\n     #       Vectorise data\\n     index           <- apc.get.index(data.list)\\n     v.response      <- data.list$response[index$index.data]\\n     v.dose          <- data.list$dose[index$index.data]\\n     \\n     #       Get design\\n     m.design        <- apc.get.design(index,\\\"APC\\\")$design\\n     \\n     #       Fit using glm.fit from stats package\\n     fit.apc.glm     <- glm.fit(m.design,v.response,family=poisson(link=\\\"log\\\"),offset=log(v.dose))\\n     \\n     #       Get canonical coefficients\\n     v.cc            <- fit.apc.glm$coefficients\\n     \\n     #       Find linear predictors and express in matrix form\\n     m.fit           <- data.list$response                   #       create matrix\\n     m.fit[index$index.data]         <- m.design \\n     m.fit.offset            <- m.fit + log(data.list$dose)  #       add offset\\n     exp(m.fit.offset)\\n     \\n     #       Compare with linear.predictors from glm.fit\\n     #       difference should be zero\\n     sum(abs(m.fit.offset[index$index.data]-fit.apc.glm$linear.predictors))\\n     \\n     #####################\\n     #       EXAMPLE 4 with Taylor-Ashe loss data\\n     #       This example illustrates the over-dispersed poisson response model.\\n     \\n     data <- data.loss.TA()\\n     fit.apc.od <- apc.fit.model(data,\\\"od.poisson.response\\\",\\\"APC\\\")\\n     fit.apc.od$coefficients.canonical[1:5,]\\n     fit.apc.no.od <- apc.fit.model(data,\\\"poisson.response\\\",\\\"APC\\\")\\n     fit.apc.no.od$coefficients.canonical[1:5,]\\n     \\n\\n\",\"type\":1},{\"output\":\"Rendering content/post/2018-03-02-HeatTolerance.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:18:20 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/answer1.Rmd\\nLoading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:18:27 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/answer2.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\n\",\"type\":2},{\"output\":\"Loading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:18:34 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/answer3.Rmd\\nLoading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:18:36 2018 \\n\",\"type\":1},{\"output\":\"Rendering content/post/answer4.Rmd\\n\",\"type\":2},{\"output\":\"Loading required package: grid\\nLoading required package: scales\\n\",\"type\":2},{\"output\":\"\\nSuccessfully loaded .Rprofile at Thu Mar  1 14:18:43 2018 \\n\",\"type\":1},{\"output\":\"Warning in find_exec(\\\"hugo\\\", \\\"Hugo\\\", \\\"You can install it via blogdown::install_hugo()\\\") :\\n  Found hugo at \\\"~/Library/Application Support/Hugo/hugo\\\" and \\\"/usr/local/bin/hugo\\\". The former will be used. If you don't need the former, you may delete it.\\n\",\"type\":2},{\"output\":\"Started building sites ...\\n\\nBuilt site for language en:\\n0 draft content\\n0 of 1 future rendered\\n0 expired content\\n46 regular pages created\\n40 other pages created\\n48 non-page files copied\\n41 paginator pages created\\n14 tags created\\n1 categories created\\ntotal in 164 ms\\n\",\"type\":1},{\"output\":\"\\nOutput created: public/index.html\\n\",\"type\":2}]"
compile_pdf_state="{\"errors\":[],\"output\":\"\",\"running\":false,\"tab_visible\":false,\"target_file\":\"\"}"
files.monitored-path=""
find-in-files-state="{\"handle\":\"\",\"input\":\"\",\"path\":\"\",\"regex\":true,\"results\":{\"file\":[],\"line\":[],\"lineValue\":[],\"matchOff\":[],\"matchOn\":[]},\"running\":false}"
imageDirtyState="1"
saveActionState="0"
