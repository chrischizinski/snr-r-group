---
title: "Ecological Detective - Probability and probability models. Part 2"
date: 2017-03-17
categories: ["R"]
tags: ["EcoDetective"]
---



<pre class="r"><code>library(tidyverse)
library(broom)</code></pre>
<p>Sources of the notes for this lecture are a combination of <a href="http://www2.cose.isu.edu/~ahoken/book/">Aho(2013)</a> (Chapters 2 and 3) and Ecological Detective (Chapters 3 and 4).</p>
<div id="common-distributions" class="section level2">
<h2>Common distributions</h2>
<div id="discrete" class="section level3">
<h3>Discrete</h3>
<div id="negative-binomial-distribution" class="section level4">
<h4>Negative binomial distribution</h4>
<ul>
<li><em>Negative binomial</em> gives the probability that x independent Bernoulli failures will occur prior to obtaining the rth success
- two parameters: <em>r</em> is the number of successes and \( \pi \) is the probability of an individual Bernoulli success</li>
</ul>
<p>First form:</p>
<p><span class="math display">\[
\mathbf{Pr(s^{th}\:success\:occurs\:on\:trial\:u + s)} = \left(\begin{array}
{c}
u + s -1 \\
u 
\end{array}\right)p^s(1-p)^u
\]</span></p>
<p>where: <em>p</em> is the probability of successes, <em>s</em> number of trials for success, and <em>u</em> is the number of not succeeding
and possible values for <em>u</em> &gt; 0 and 0 &lt; <em>p</em> &gt; 1.</p>
<p>Second form:<br />
Assumes that the rate parameter has its own probability distribution.</p>
<p><span class="math display">\[
\mathbf{Pr(s^{th}\:success\:occurs\:on\:trial\:u + s)} = \left(\begin{array}
{c}
n + s -1 \\
s 
\end{array}\right)p^n(1-p)^s
\]</span></p>
<p>where <em>n</em> can be any value and not just <em>n</em> &gt; 0. <em>n</em> is often called the “over dispersion” parameter</p>
<p>The mean of the <em>negative binomial</em> is</p>
<p><span class="math display">\[ 
E(Z(t)) = \frac{n(1-p)}{p} = \frac{n}{a}t = m(t) 
\]</span></p>
<p>The variance of the <em>negative binomial</em> is
<span class="math display">\[
VAR(Z(t)) =  m(t) + \frac{m(t)^2}{n}
\]</span></p>
<p>Suppose, species <em>A</em> has a 0.10 probability of occurring in any given plot. What is the probability of systematically exploring 0 to 150 plots to find 5 organisms, if we know the organism distribution follows a negative binomial distribution?</p>
<pre class="r"><code>x &lt;- 0:150
size &lt;- 5
prob = 0.1
nb_data&lt;-data.frame(x = x, size = size, pdf = dnbinom(x = x, size = size, prob = prob))

head(nb_data)</code></pre>
<pre><code>##   x size          pdf
## 1 0    5 0.0000100000
## 2 1    5 0.0000450000
## 3 2    5 0.0001215000
## 4 3    5 0.0002551500
## 5 4    5 0.0004592700
## 6 5    5 0.0007440174</code></pre>
<p>Plot it</p>
<pre class="r"><code>ggplot(data = nb_data) +
  geom_bar(aes(x = x, y = pdf), stat = &quot;identity&quot;, width = 0.85) + 
  coord_cartesian(ylim = c(0,0.025), xlim = c(0, 150), expand = FALSE) +
  scale_x_continuous(breaks = seq(0,150, by = 5)) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>What is the probability of finding 5 of species <em>A</em> in 35 plots?</p>
<pre class="r"><code>sum(dnbinom(0:35, size = 5, prob = 0.10))</code></pre>
<pre><code>## [1] 0.3709823</code></pre>
<pre class="r"><code>#or
pnbinom(35, size = 5, prob = 0.10)</code></pre>
<pre><code>## [1] 0.3709823</code></pre>
<p>Alternative specification uses the mean <em>mu</em> rather than the rate <em>p</em>.</p>
<p>From the help for <code>dbinom()</code>:</p>
<blockquote>
<p>An alternative parametrization (often used in ecology) is by the mean mu, and size, the dispersion parameter, where prob = size/(size+mu). The variance is mu + mu^2/size in this parametrization. &lt;</p>
</blockquote>
<p>Suppose, species <em>A</em> that it has been shown that it takes approximately 25 areas to search before you have 5 organisms. What is the probability of systematically exploring 0 to 150 plots to find 5 organisms, if we know the organism distribution follows a negative binomial distribution with a mean of 25?</p>
<pre class="r"><code>x &lt;- 0:150
size &lt;- 5
mu = 25
nb_data2&lt;-data.frame(x = x, size = size, pdf = dnbinom(x = x, size = size, mu = mu))

ggplot(data = nb_data2) +
  geom_bar(aes(x = x, y = pdf), stat = &quot;identity&quot;, width = 0.85) + 
  coord_cartesian(ylim = c(0,0.04), xlim = c(0, 150), expand = FALSE) +
  scale_x_continuous(breaks = seq(0,150, by = 5)) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
</div>
<div id="continuous" class="section level3">
<h3>Continuous</h3>
<div id="normal-or-gaussian" class="section level4">
<h4>Normal or Gaussian</h4>
<ul>
<li>Most commonly used continuous pdf in statistics is the <em>normal distribution</em> or <em>Gaussian distribution</em></li>
<li>It is used to represent processes where the most likely outcome is the average and it is symmetric around the average</li>
<li>Two parameters are \( \mu \) <em>mean</em> and \( \sigma \) <em>standard deviation</em></li>
<li>expected outcomes for \( x \in {\rm I\!R} \) and \( \sigma &gt; 0 \)</li>
</ul>
<div id="standard-normal-or-z-distribution" class="section level5">
<h5>Standard normal or Z-distribution</h5>
<ul>
<li>\( \mu = 0\) and \( \sigma = 1 \)</li>
</ul>
<p>Suppose the mean tarsus length of an adult pheasant is 72.5 mm and the standard deviation is 2.36. Assuming this follows a normal distribution, construct a pdf from 60 mm to 85 mm.</p>
<pre class="r"><code>x&lt;- seq(60,85, by = 0.01)
sd = 2.36
mu = 72.5

nrm_data&lt;-data.frame(x = x, sd = sd, mean = mu, pdf = dnorm(x = x, mean = mu, sd = sd))

head(nrm_data)</code></pre>
<pre><code>##       x   sd mean             pdf
## 1 60.00 2.36 72.5 0.0000001368145
## 2 60.01 2.36 72.5 0.0000001399185
## 3 60.02 2.36 72.5 0.0000001430904
## 4 60.03 2.36 72.5 0.0000001463316
## 5 60.04 2.36 72.5 0.0000001496434
## 6 60.05 2.36 72.5 0.0000001530275</code></pre>
<p>and plot it out.</p>
<pre class="r"><code>ggplot(data = nrm_data) +
  geom_line(aes(x = x, y = pdf)) + 
  coord_cartesian(ylim = c(0,0.20), xlim = c(60, 85), expand = FALSE) +
  labs(x = &quot;Tarsus length&quot;, y = &quot;density&quot;) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>What is the probability that the tarsus length is at least 68 mm?</p>
<pre class="r"><code>sd_away &lt;- ((68 - mu)/sd) 
norm_function&lt;-function(x){1/sqrt(2 * pi) * exp(-1/2 * x^2)}

integrate(norm_function, lower= -Inf, upper=sd_away)</code></pre>
<pre><code>## 0.02827456 with absolute error &lt; 0.000025</code></pre>
<pre class="r"><code>#or

integrate(dnorm,-Inf, sd_away)</code></pre>
<pre><code>## 0.02827456 with absolute error &lt; 0.000025</code></pre>
<pre class="r"><code># or
pnorm(sd_away)</code></pre>
<pre><code>## [1] 0.02827456</code></pre>
<p>What is the probability that the tarsus length is between 68 mm and 70 mm?</p>
<pre class="r"><code>sd_away1 &lt;- ((68 - mu)/sd) 
sd_away2 &lt;- ((70 - mu)/sd) 


integrate(dnorm,sd_away1, sd_away2)</code></pre>
<pre><code>## 0.116452 with absolute error &lt; 1.3e-15</code></pre>
<pre class="r"><code>ggplot(data = nrm_data) +
  geom_ribbon(data = nrm_data[nrm_data&gt;= 68 &amp; nrm_data &lt;=70, ],aes(x = x, ymin = 0, ymax = pdf), fill = &quot;lightblue&quot;) +
  geom_line(aes(x = x, y = pdf)) +
  coord_cartesian(ylim = c(0,0.20), xlim = c(60, 85), expand = FALSE) +
  labs(x = &quot;Tarsus length&quot;, y = &quot;density&quot;) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
</div>
<div id="lognormal-distribution" class="section level4">
<h4>Lognormal distribution</h4>
<p>If a random variable X has a log normal distribution, and Y = log(X), then Y will have a normal distribution.</p>
<p>Correspondingly, if Y is normally distributed then \( e^Y \) will be lognormally distributed.</p>
<ul>
<li>Two parameters are \( \mu \) <em>location parameter</em> and \( \sigma \) <em>scale parametre</em></li>
<li><p>expected outcomes for \( \mu \in {\rm I\!R} \) and \( \sigma &gt; 0 \)</p></li>
<li><p>Many variables in biology have lognormal distributions (cannot be less than zero, are right-skewed) and are normally distributed after log-transformation</p></li>
</ul>
<pre class="r"><code>ln_data &lt;- data.frame(x = c(0:15), 
                      pdf1 = dlnorm(x = c(0:15), meanlog = 0, sdlog = 1),
                      pdf2 = dlnorm(x = c(0:15), meanlog = 0, sdlog = 5),
                      pdf3 = dlnorm(x = c(0:15), meanlog = 2, sdlog = 1)
                      )

ggplot(data = ln_data) +
  geom_line(aes(x = x, y = pdf1) ,colour = &quot;red&quot;, size = 1) +
  geom_line(aes(x = x, y = pdf2) ,colour = &quot;blue&quot;, size = 1) +
  geom_line(aes(x = x, y = pdf3) ,colour = &quot;purple&quot;, size = 1) +
  coord_cartesian(ylim = c(0,0.50), xlim = c(0,15), expand = FALSE) +
  labs(x = &quot;X&quot;, y = &quot;density&quot;) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="chi-square-distribution" class="section level4">
<h4>Chi-square distribution</h4>
<ul>
<li>The \( \chi^2 \) is defined by the <em>degrees of freedom</em> (the number of independent pieces of information that exist concerning an estimable parameter)</li>
<li>The \( \chi^2 \) distribution is frequently used for testing the null hypothesis that observed and expected frequencies are equal</li>
<li>The \( \chi^2 \) distribution results from the summing of independent, squared, standard normal distributions</li>
<li><p>Has the following form:
<span class="math display">\[ f(x) = \frac{1}{2^{v/2}\Gamma(v/2)}x^{(v/2)-1}e^{-x/2} \]</span></p>
<ul>
<li>where outcomes are continuous and independent, \(x \geq 0 \), \(v \geq 0 \), and \( \Gamma(.) \) is the gamma function.</li>
<li>\( \Gamma(x)= (x-1)!\)</li>
</ul></li>
</ul>
<pre class="r"><code>x = 6
factorial(x - 1)</code></pre>
<pre><code>## [1] 120</code></pre>
<pre class="r"><code>gamma(x)</code></pre>
<pre><code>## [1] 120</code></pre>
<p>Let’s explore the relationship between the standard normal and the \( \chi^2 \) distribution by generating 10000 standard random normal values. We will then \( x^2 \) thos values and compare the distributions.</p>
<pre class="r"><code>set.seed(12345)

#generate standard normal
rand.data&lt;-data.frame(std_norm = rnorm(10000))

# plot the density of those values
ggplot(data = rand.data) + 
  geom_density(aes(x = std_norm), fill = &quot;lightblue&quot;) +
  coord_cartesian(xlim = c(-4,4), ylim = c(0,0.5), expand = FALSE) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code># square our standard normal
rand.data$chi &lt;- rand.data$std_norm^2

# plot the density of those values
ggplot(data = rand.data) + 
  geom_density(aes(x = chi), fill = &quot;red&quot;) +
  coord_cartesian(xlim = c(0,15), ylim = c(0,1.25), expand = FALSE) +
  annotate(&quot;text&quot;, x = 5, y = 0.75, parse = T, label = as.character(expression(paste(~chi^2,&quot;distribution with 1 df&quot;))), size = 6, hjust = 0.2) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-12-2.png" width="672" /></p>
<p>The degrees of freedom is equal to the \( \mu \), variance is equal to 2*df, and mode is df - 2</p>
<p>Lets look at the \( \chi^2 \) distribution with varying degrees of freedom.</p>
<pre class="r"><code>x = 0:25
chi_data &lt;- data.frame(x = x,
                       df1 = dchisq(x,1),
                       df3 = dchisq(x,3),
                       df6 = dchisq(x,6),
                       df12 = dchisq(x,12))

chi_data %&gt;% 
  gather(df, value, df1:df12) %&gt;% 
  mutate(df = factor(df, levels = c(&quot;df1&quot;,&quot;df3&quot;,&quot;df6&quot;,&quot;df12&quot;))) -&gt; chi_data

ggplot(data = chi_data) +
  geom_line(aes(x = x, y = value, colour = df, group = df), size = 1) + 
  coord_cartesian(xlim = c(0,25), ylim = c(0,0.25), expand = FALSE) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="gamma-distribution" class="section level4">
<h4>Gamma distribution</h4>
<ul>
<li>The gamma distribution is named after the gamma functioned described above.<br />
</li>
<li>\( \theta\) is the scale parameter and \( \kappa\) is the shape parameter</li>
<li>Outcomes are continuous and independent, x &gt; 0 and \( \theta &gt;0\), \( \kappa &gt;0\)</li>
<li>The mean is \( \theta * \kappa \)</li>
<li>The gamma distribution is most frequently used for representing phenomena with highly right-skewed probability distributions
<ul>
<li>However it is extremely flexible and can be used to mimic other pdfs</li>
</ul></li>
</ul>
<pre class="r"><code>x = 0:30
gamm_data &lt;- rbind(data.frame(type = &quot;vary shape&quot;, scale = 5, shape = 1, x = x, y =  dgamma(x = x, shape = 1, scale = 2)),
                   data.frame(type = &quot;vary shape&quot;,scale = 5, shape = 10, x = x, y =  dgamma(x = x, shape = 2, scale = 2)),
                   data.frame(type = &quot;vary shape&quot;,scale = 5, shape = 20, x = x, y =  dgamma(x = x, shape = 3, scale = 2)))
                   

gamm_data2 &lt;- rbind(data.frame(type = &quot;vary scale&quot;,scale = 1, shape = 10, x = x, y =  dgamma(x = x, shape = 2, scale = 1)),
                   data.frame(type = &quot;vary scale&quot;,scale = 5, shape = 10, x = x, y =  dgamma(x = x, shape = 2, scale = 2)),
                   data.frame(type = &quot;vary scale&quot;,scale = 10, shape = 10, x = x, y =  dgamma(x = x, shape = 2, scale = 3)))

all_gamm_data &lt;- rbind(gamm_data, gamm_data2)
all_gamm_data$type &lt;- factor(all_gamm_data$type, levels = c(&quot;vary shape&quot;, &quot;vary scale&quot;))
                   
                   
ggplot(data = all_gamm_data) +
  geom_line(aes(x = x, y = y, colour = paste(scale, shape), group = paste(scale, shape)), size = 1) + 
  coord_cartesian(xlim = c(0,30), ylim = c(0,0.5), expand = FALSE) +
  scale_x_continuous(breaks = seq(0,30, by = 5)) +
  facet_wrap(~type) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="monte-carlo-methods" class="section level2">
<h2>Monte Carlo Methods</h2>
<ul>
<li>In order to confront models with data, we need to estimate parameters and choose one description over another</li>
<li>In most cases, we do not know the underlying mechanisms and processes</li>
<li>One way to test our confidence in our models is to test models on sets of simulated data that we construct with known mechanisms and processes (<em>Monte Carlo</em> or <em>stochastic simulation</em>)</li>
<li><p>Monte Carlo methods uses random-number generators to construct data</p></li>
<li><p>One type of random number generator is the random uniform (<code>runif()</code> in R) that generates continuous values between a minimum (usually 0) and maximum (usually 1) where probability of each value being drawn is equal</p></li>
<li><p>Other distributions inclue: binomial (<code>rbinom()</code> in R), Poisson (<code>rpois()</code> in R), negative binomial (<code>rnbinom()</code> in R), normal (<code>rnorm()</code> in R), gamma (<code>rgamma()</code> in R), and many others</p></li>
</ul>
<div id="ecological-scenarios-simple-population-model-with-process-and-observation-uncertainty" class="section level3">
<h3>Ecological scenarios: Simple population model with process and observation uncertainty</h3>
<p>** What are the differences between process and observation uncertainty? **</p>
<p>We can use Monte Carlo simulations to explore process and observation uncertainty in a simple population model</p>
<p><span class="math display">\[ N_{t +1} = sN_t + b_t + W_t \]</span>
<span class="math display">\[ N_{obs,t} = N_t + V_t \]</span></p>
<pre class="r"><code>#Psuedocode 3.4
set.seed(54321)

s = 0.8
b = 20
N0 = 50 
sig_w = 10 # process uncertainty, random normal with mean 0 and sd = 10
sig_v = c(0,10) # observation uncertainty, random normal with mean 0 and sd 0 and 10

Nt = N0
t_total = 50 + 1

N_stor &lt;- as.data.frame(matrix(0, t_total,3))
names(N_stor) &lt;- c(&quot;Nt&quot;, &quot;Nobs0&quot;, &quot;Nobs10&quot;)

for(t in 1:t_total){
  N_stor$Nt[t]&lt;-Nt # Place the population number at time t in  N_stor
  Nt_1 = s*Nt + b + rnorm(1,mean = 0, sd = sig_w) # Calculate the population at t + 1
  N_obs0 = Nt + rnorm(1,mean = 0, sd = sig_v[1]) # Calculate observation error (none)
  N_stor$Nobs0[t]&lt;-N_obs0 # Place the observed population number at time t in  N_stor 
  N_obs10 = Nt + rnorm(1,mean = 0, sd = sig_v[2]) # Calculate observation error (none)
  N_stor$Nobs10[t]&lt;-N_obs10 # Place the observed population number at time t in  N_stor 
  Nt &lt;- Nt_1 # change Nt to Nt+1
  }

head(N_stor)</code></pre>
<pre><code>##         Nt    Nobs0   Nobs10
## 1 50.00000 50.00000 40.71956
## 2 58.21099 58.21099 41.70499
## 3 58.72846 58.72846 47.77316
## 4 62.90210 62.90210 88.06256
## 5 53.39926 53.39926 55.19903
## 6 76.67293 76.67293 89.31436</code></pre>
<p>Lets look a plot of population at time t and population at t + 1 (Figure 3.6)</p>
<pre class="r"><code>lagged_data&lt;-data.frame(Nt =N_stor$Nt[-51], Nt_1 = N_stor$Nt[-1])

lm_mod&lt;- lm(Nt~Nt_1, data = lagged_data)
summary(lm_mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Nt ~ Nt_1, data = lagged_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -24.8374  -7.2374  -0.5361   7.4813  24.4717 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 15.55382    8.13203   1.913   0.0618 .  
## Nt_1         0.81754    0.09155   8.930 8.98e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 10.93 on 48 degrees of freedom
## Multiple R-squared:  0.6243, Adjusted R-squared:  0.6164 
## F-statistic: 79.75 on 1 and 48 DF,  p-value: 8.979e-12</code></pre>
<pre class="r"><code>newdata &lt;- data.frame(Nt_1 = 0:160)

pred_mod &lt;- augment(lm_mod, newdata = newdata) 

ggplot(data = lagged_data) + 
  geom_line(data = pred_mod, aes(x = Nt_1, y = .fitted), linetype = &quot;dashed&quot;) + 
  geom_point(aes(x = Nt_1, y = Nt), size = 2, shape = 1, colour = &quot;red&quot;) + 
  coord_cartesian(ylim = c(0, 150), xlim = c(0, 150), expand = FALSE) +
  labs(x = &quot;Population size at time t + 1&quot;, y = &quot;Population size at time t&quot;) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>We can see in this figure that the process uncertainty (remember we did not look at observation uncertainty) influences the values by scattering the points along the mean (regression line). However, there is still a strong relationship between the two values ((\(R^2\) = 0.6242727)). We can see that the birth rate (15.5538219) is close to our birth rate (20) and the survival rate (0.8175352) is close to our survival rate (0.8).</p>
<p>Now let’s look at the influence of observation uncertainty with a plot of observed population at time t and observed population at t + 1 (Figure 3.7)</p>
<pre class="r"><code>lagged_data2&lt;-data.frame(Nobs10 =N_stor$Nobs10[-51], Nobs10_1 = N_stor$Nobs10[-1])

lm_mod2&lt;- lm(Nobs10~Nobs10_1, data = lagged_data2)
summary(lm_mod2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Nobs10 ~ Nobs10_1, data = lagged_data2)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -39.61 -15.56   3.88  12.54  31.26 
## 
## Coefficients:
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  35.7564    11.2686   3.173   0.00263 ** 
## Nobs10_1      0.5863     0.1251   4.685 0.0000233 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 17.55 on 48 degrees of freedom
## Multiple R-squared:  0.3138, Adjusted R-squared:  0.2995 
## F-statistic: 21.95 on 1 and 48 DF,  p-value: 0.00002334</code></pre>
<pre class="r"><code>newdata &lt;- data.frame(Nobs10_1 = 0:160)

pred_mod2 &lt;- augment(lm_mod2, newdata = newdata) 

ggplot(data = lagged_data2) + 
  geom_line(data = pred_mod2, aes(x = Nobs10_1, y = .fitted), linetype = &quot;dashed&quot;) + 
  geom_point(aes(x = Nobs10_1, y = Nobs10), size = 2, shape = 1, colour = &quot;blue&quot;) + 
  coord_cartesian(ylim = c(0, 150), xlim = c(0, 150), expand = FALSE) +
  labs(x = &quot;Observed population size at time t + 1&quot;, y = &quot;Observed population size at time t&quot;) +
  theme_bw()</code></pre>
<p><img src="/post/2017-03-17-EcologicalDetective6_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>We can see in this figure that the process uncertainty and observation uncertainty we start getting a much weaker relationship (\(R^2\) = 0.3138051) by scattering the points even more along the mean. We also see that the birth rate (35.7563572) is off from our specified birth rate (20), as is the survival rate (0.5862988) compared to our specified survival rate (0.8).</p>
</div>
</div>
