---
title: "Ecological Detective -- Relationships and probability"
date: 2017-02-23
categories: ["R"]
tags: ["EcoDetective"]
---



<div id="exploring-the-relationship-between-two-variables" class="section level2">
<h2>Exploring the relationship between two variables</h2>
<p>First lets bring in the data from the previous lesson</p>
<pre class="r"><code>library(tidyverse)
library(broom)</code></pre>
<pre class="r"><code>fish_data &lt;- read_csv(&quot;https://raw.githubusercontent.com/chrischizinski/MWFWC_FishR/master/CourseMaterial/data/wrkshp_data.csv&quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   .default = col_character(),
##   WaterbodyCode = col_integer(),
##   Area = col_integer(),
##   MethodCode = col_integer(),
##   surveydate = col_datetime(format = &quot;&quot;),
##   Station = col_integer(),
##   Effort = col_integer(),
##   SpeciesCode = col_integer(),
##   LengthGroup = col_integer(),
##   FishCount = col_integer(),
##   FishLength = col_integer(),
##   FishWeight = col_integer(),
##   Age = col_integer(),
##   Edge = col_integer(),
##   Annulus1 = col_integer(),
##   Annulus2 = col_integer(),
##   Annulus3 = col_integer(),
##   Annulus4 = col_integer(),
##   Annulus5 = col_integer(),
##   Annulus6 = col_integer(),
##   Annulus7 = col_integer()
##   # ... with 2 more columns
## )</code></pre>
<pre><code>## See spec(...) for full column specifications.</code></pre>
<pre class="r"><code>fish_data %&gt;% 
  select(WaterbodyCode:Age) %&gt;% 
  mutate(Age = as.numeric(Age)) %&gt;% 
  filter(!is.na(Age),
         WaterbodyCode == 4999,
         SpeciesCode %in% c(780)) -&gt; FishAge  </code></pre>
<p>Now lets plot the basic relationship between age and length of this species.</p>
<pre class="r"><code>ggplot(data = FishAge) +
  geom_point(aes(x = Age, y = FishLength), size = 3, alpha = 0.35, colour = &quot;red&quot;) +
  theme_bw()</code></pre>
<p><img src="/www.snr-r-group.netlify.compost/2017-02-23-EcologicalDetective3_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>How does fish age relate to fish length?</p>
<ol style="list-style-type: decimal">
<li>Linear</li>
<li>Polynomial</li>
<li>Logarithmic</li>
<li>Non-linear</li>
</ol>
<pre class="r"><code># linear response
lm_mod &lt;- lm(FishLength ~ Age, data = FishAge)
summary(lm_mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = FishLength ~ Age, data = FishAge)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -94.265 -19.517   0.703  21.953  58.725 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  173.254      6.232  27.799  &lt; 2e-16 ***
## Age           17.011      2.138   7.957  9.8e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 29.81 on 80 degrees of freedom
## Multiple R-squared:  0.4418, Adjusted R-squared:  0.4348 
## F-statistic: 63.32 on 1 and 80 DF,  p-value: 9.797e-12</code></pre>
<pre class="r"><code># polynomial response
poly_mod &lt;- lm(FishLength ~ poly(Age,3), data = FishAge)
summary(poly_mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = FishLength ~ poly(Age, 3), data = FishAge)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -92.393 -18.407  -1.423  19.566  49.441 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    215.366      3.011  71.527  &lt; 2e-16 ***
## poly(Age, 3)1  237.206     27.266   8.700 4.13e-13 ***
## poly(Age, 3)2 -107.773     27.266  -3.953 0.000169 ***
## poly(Age, 3)3   38.539     27.266   1.413 0.161501    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 27.27 on 78 degrees of freedom
## Multiple R-squared:  0.5447, Adjusted R-squared:  0.5272 
## F-statistic:  31.1 on 3 and 78 DF,  p-value: 2.506e-13</code></pre>
<pre class="r"><code># logarithmic

log_mod &lt;- lm(FishLength ~ log(Age +1), data = FishAge)
summary(log_mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = FishLength ~ log(Age + 1), data = FishAge)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -93.378 -17.928  -2.378  18.426  52.822 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   148.691      7.462  19.925  &lt; 2e-16 ***
## log(Age + 1)   58.699      6.023   9.745 3.04e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 26.98 on 80 degrees of freedom
## Multiple R-squared:  0.5428, Adjusted R-squared:  0.5371 
## F-statistic: 94.97 on 1 and 80 DF,  p-value: 3.039e-15</code></pre>
<pre class="r"><code># non linear

nl_mod &lt;- nls(FishLength ~ exp(a + Age*b), start = list(a = 0, b = 1), data = FishAge)
summary(nl_mod)</code></pre>
<pre><code>## 
## Formula: FishLength ~ exp(a + Age * b)
## 
## Parameters:
##   Estimate Std. Error t value Pr(&gt;|t|)    
## a 5.191797   0.031178 166.522  &lt; 2e-16 ***
## b 0.070687   0.009528   7.419  1.1e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 30.64 on 80 degrees of freedom
## 
## Number of iterations to convergence: 7 
## Achieved convergence tolerance: 0.00000223</code></pre>
<p>Plot the curves to the data</p>
<pre class="r"><code>newdata &lt;- data.frame(Age = seq(0,8,by = 1))

lm_pred&lt;- data.frame(model = &quot;linear&quot;,augment(lm_mod, newdata = newdata))

poly_pred&lt;- data.frame(model = &quot;polynomial&quot;,augment(poly_mod, newdata = newdata))

log_pred&lt;- data.frame(model = &quot;log&quot;,augment(log_mod, newdata = newdata))
# log_pred$.fitted &lt;- exp(log_pred$.fitted) 

nl_pred&lt;- data.frame(model = &quot;nonlinear&quot;,augment(nl_mod, newdata = newdata))
nl_pred$.se.fit&lt;-NA

all.pred&lt;- rbind(lm_pred,poly_pred,log_pred,nl_pred)

ggplot(data = FishAge) +
  geom_point(aes(x = Age, y = FishLength), size = 1, alpha = 0.35, colour = &quot;red&quot;) +
  geom_line(data=all.pred, aes(x = Age, y = .fitted, colour = model)) +
  theme_bw()</code></pre>
<p><img src="/www.snr-r-group.netlify.compost/2017-02-23-EcologicalDetective3_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Lets look at the distribution of the residuals of each model to the actual data. What would you expect to see?</p>
<pre class="r"><code>resid_lm&lt;-data.frame(model = &quot;linear&quot;,resid = augment(lm_mod)$.resid)
resid_log&lt;-data.frame(model = &quot;log&quot;,resid = augment(log_mod)$.resid)
resid_poly&lt;-data.frame(model = &quot;poly&quot;,resid = augment(poly_mod)$.resid)
resid_nl&lt;-data.frame(model = &quot;nonlinear&quot;,resid = augment(nl_mod)$.resid)


all_resid&lt;-rbind(resid_lm, resid_log, resid_poly, resid_nl)
head(all_resid)</code></pre>
<pre><code>##    model       resid
## 1 linear -44.3284415
## 2 linear   7.7139542
## 3 linear -12.2754468
## 4 linear  22.7033553
## 5 linear -13.3178426
## 6 linear  -0.3072437</code></pre>
<pre class="r"><code>glimpse(all_resid)</code></pre>
<pre><code>## Observations: 328
## Variables: 2
## $ model &lt;chr&gt; &quot;linear&quot;, &quot;linear&quot;, &quot;linear&quot;, &quot;linear&quot;, &quot;linear&quot;, &quot;linea...
## $ resid &lt;dbl&gt; -44.3284415, 7.7139542, -12.2754468, 22.7033553, -13.317...</code></pre>
<pre class="r"><code>ggplot(data = all_resid) +
  geom_violin(aes(x = model, y  =resid, fill = model)) + 
  theme_bw()</code></pre>
<p><img src="/www.snr-r-group.netlify.compost/2017-02-23-EcologicalDetective3_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="experiments-events-and-probability" class="section level2">
<h2>Experiments, Events, and Probability</h2>
<ul>
<li><p>In probability theory, we are concerned with the occurence of events that can be thought of as outcomes of experiments</p></li>
<li><p>The probability of event A occurring is \( Pr { A } \) = probability that the event occurs</p></li>
<li><p>The <em>Frequentist</em> interpretation of probability \( Pr { A } \) is the proportion of A outcomes as the total number of trials in an experiment goes to infinity.</p></li>
</ul>
<p>Coin flipping example:</p>
<p>For example, it can be demonstrated that the proportion of heads from a series of fair coin flips will approach the constant 0.5 as the number of trials grows large, that is, \( Pr { Head } \) = 0.5</p>
<pre class="r"><code>## Binomial distribution
?rbinom
set.seed(12345)

N_flips&lt;-data.frame(N = c(1:5000))
N_flips$N_heads &lt;- unlist(lapply(lapply(N_flips$N, rbinom, size = 1, prob = 0.50), sum))
N_flips$prop &lt;- N_flips$N_heads/N_flips$N

head(N_flips)</code></pre>
<pre><code>##   N N_heads      prop
## 1 1       1 1.0000000
## 2 2       2 1.0000000
## 3 3       1 0.3333333
## 4 4       3 0.7500000
## 5 5       1 0.2000000
## 6 6       1 0.1666667</code></pre>
<p>If we look at the first 100, you can see</p>
<pre class="r"><code>ggplot(data = N_flips) +
  geom_line(aes(x = N, y = prop)) + 
  geom_hline(aes(yintercept = 0.5), colour = &quot;red&quot;, linetype = &quot;dotted&quot;) +
  coord_cartesian(xlim = c(0, 100)) +
  theme_bw()</code></pre>
<p><img src="/www.snr-r-group.netlify.compost/2017-02-23-EcologicalDetective3_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Lets look at the whole range</p>
<pre class="r"><code>ggplot(data = N_flips) +
  geom_line(aes(x = N, y = prop)) + 
  geom_hline(aes(yintercept = 0.5), colour = &quot;red&quot;, linetype = &quot;dotted&quot;) +
  coord_cartesian(xlim = c(0, 5000)) +
  theme_bw()</code></pre>
<p><img src="/www.snr-r-group.netlify.compost/2017-02-23-EcologicalDetective3_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<ul>
<li><p>The <em>Bayesian</em> interpretation of probability is the degrees of belief. For a Bayesian, \( Pr{A}\) is a measure of certainty; a quantication of an investigatorâ€™s belief that A is true.</p></li>
<li><p>Differences in Frequentist and Bayesian perspectives are most important pertaining to inferential procedures (e.g., parameter estimation and hypothesis testing). They are irrelevant to the mathematical principles of probability.</p></li>
</ul>
</div>
